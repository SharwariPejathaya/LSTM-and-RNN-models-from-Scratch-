{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b2b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "class Config:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    BATCH_SIZE = 32\n",
    "    EMBEDDING_DIM = 100\n",
    "    HIDDEN_DIM = 128\n",
    "    NUM_EPOCHS = 10\n",
    "    LEARNING_RATE = 0.001\n",
    "    PAD_TOKEN = \"<pad>\"\n",
    "    UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "print(f\"Using device: {Config.DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42281525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch LSTM implementation is defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ScratchLSTMCell(nn.Module):\n",
    "    \"\"\"A single step of a Long Short-Term Memory network.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(input_size + hidden_size, 4 * hidden_size, bias=True)\n",
    "\n",
    "    def forward(self, x, states):\n",
    "        h_prev, c_prev = states\n",
    "        combined = torch.cat([x, h_prev], dim=1)\n",
    "        gates = self.W(combined)\n",
    "        \n",
    "        \n",
    "        i, f, g, o = torch.chunk(gates, 4, dim=1)\n",
    "        \n",
    "        c_next = torch.sigmoid(f) * c_prev + torch.sigmoid(i) * torch.tanh(g)\n",
    "        h_next = torch.sigmoid(o) * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "class ScratchLSTM(nn.Module):\n",
    "    \"\"\"A multi-step LSTM layer that processes a sequence.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.forward_cell = ScratchLSTMCell(input_size, hidden_size)\n",
    "        if self.bidirectional:\n",
    "            self.backward_cell = ScratchLSTMCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        h0 = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(batch_size, self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs_fwd = []\n",
    "        h_t, c_t = (h0, c0)\n",
    "        for t in range(seq_len):\n",
    "            h_t, c_t = self.forward_cell(x[:, t, :], (h_t, c_t))\n",
    "            outputs_fwd.append(h_t)\n",
    "        final_h_fwd, final_c_fwd = h_t, c_t\n",
    "        outputs_fwd = torch.stack(outputs_fwd, dim=1)\n",
    "\n",
    "        if not self.bidirectional:\n",
    "            return outputs_fwd, (final_h_fwd.unsqueeze(0), final_c_fwd.unsqueeze(0))\n",
    "\n",
    "        # Backward pass\n",
    "        outputs_bwd = []\n",
    "        h_t, c_t = (h0, c0)\n",
    "        for t in reversed(range(seq_len)):\n",
    "            h_t, c_t = self.backward_cell(x[:, t, :], (h_t, c_t))\n",
    "            outputs_bwd.insert(0, h_t)\n",
    "        final_h_bwd, final_c_bwd = h_t, c_t\n",
    "        outputs_bwd = torch.stack(outputs_bwd, dim=1)\n",
    "\n",
    "        outputs = torch.cat([outputs_fwd, outputs_bwd], dim=2)\n",
    "        final_h = torch.stack([final_h_fwd, final_h_bwd], dim=0)\n",
    "        final_c = torch.stack([final_c_fwd, final_c_bwd], dim=0)\n",
    "        return outputs, (final_h, final_c)\n",
    "\n",
    "print(\"Scratch LSTM implementation is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed0a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_actual_slurp_data_fixed():\n",
    "    \"\"\"Load and preprocess ACTUAL SLURP dataset with WORKING span-based entities\"\"\"\n",
    "    print(\"Loading ACTUAL SLURP dataset with working span alignment...\")\n",
    "    \n",
    "    def read_slurp_file(file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line.strip()))\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        train_data = read_slurp_file(\"slurp/train.jsonl\")\n",
    "        test_data = read_slurp_file(\"slurp/test.jsonl\")\n",
    "        print(f\"ACTUAL SLURP Dataset: {len(train_data)} train, {len(test_data)} test examples\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading SLURP data: {e}\")\n",
    "        raise\n",
    "    \n",
    "  \n",
    "    word_counter = Counter()\n",
    "    intent_labels = set()\n",
    "    slot_labels = set(['O'])\n",
    "    \n",
    "    print(\"Building vocabulary from ACTUAL SLURP data...\")\n",
    "    for split_data in [train_data, test_data]:\n",
    "        for item in split_data:\n",
    "            sentence = item['sentence']\n",
    "            tokens = sentence.split()\n",
    "            word_counter.update([token.lower() for token in tokens])\n",
    "            \n",
    "            scenario = item['scenario']\n",
    "            action = item['action']\n",
    "            intent = f\"{scenario}_{action}\"\n",
    "            intent_labels.add(intent)\n",
    "            \n",
    "            \n",
    "            entities = item.get('entities', [])\n",
    "            for entity in entities:\n",
    "                slot_type = entity.get('type', 'unknown')\n",
    "                slot_labels.add(f\"B-{slot_type}\")\n",
    "                slot_labels.add(f\"I-{slot_type}\")\n",
    "   \n",
    "    word_vocab = {Config.PAD_TOKEN: 0, Config.UNK_TOKEN: 1}\n",
    "    for i, word in enumerate(word_counter, start=2):\n",
    "        word_vocab[word] = i\n",
    "    \n",
    "    intent_vocab = {intent: i for i, intent in enumerate(intent_labels)}\n",
    "    slot_vocab = {slot: i for i, slot in enumerate(slot_labels)}\n",
    "    \n",
    "   \n",
    "    idx_to_intent = {i: intent for intent, i in intent_vocab.items()}\n",
    "    idx_to_slot = {i: slot for slot, i in slot_vocab.items()}\n",
    "    \n",
    "    vocabs = {\n",
    "        \"word\": word_vocab, \n",
    "        \"intent\": intent_vocab, \n",
    "        \"slot\": slot_vocab,\n",
    "        \"idx_to_intent\": idx_to_intent,\n",
    "        \"idx_to_slot\": idx_to_slot\n",
    "    }\n",
    "    \n",
    "    print(f\"ACTUAL SLURP Vocab: {len(word_vocab)} words, {len(intent_vocab)} intents, {len(slot_vocab)} slots\")\n",
    "    \n",
    "    return train_data, test_data, vocabs\n",
    "\n",
    "class FixedActualSLURPDataset(Dataset):\n",
    "    def __init__(self, data, vocabs):\n",
    "        self.data = data\n",
    "        self.vocabs = vocabs\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        sentence = item['sentence']\n",
    "        raw_tokens = sentence.split()\n",
    "        \n",
    "        \n",
    "        tokens = []\n",
    "        for token in raw_tokens:\n",
    "            token_idx = self.vocabs['word'].get(token.lower(), self.vocabs['word'][Config.UNK_TOKEN])\n",
    "            tokens.append(token_idx)\n",
    "        \n",
    "        \n",
    "        scenario = item['scenario']\n",
    "        action = item['action']\n",
    "        intent = f\"{scenario}_{action}\"\n",
    "        intent_label = self.vocabs['intent'][intent]\n",
    "        \n",
    "        \n",
    "        slot_labels = [self.vocabs['slot']['O']] * len(raw_tokens)\n",
    "        \n",
    "        entities = item.get('entities', [])\n",
    "        \n",
    "        \n",
    "        char_to_token = {}\n",
    "        current_char = 0\n",
    "        \n",
    "        for token_idx, token in enumerate(raw_tokens):\n",
    "           \n",
    "            for _ in range(len(token)):\n",
    "                char_to_token[current_char] = token_idx\n",
    "                current_char += 1\n",
    "            \n",
    "            current_char += 1\n",
    "        \n",
    "        for entity in entities:\n",
    "            if not isinstance(entity, dict):\n",
    "                continue\n",
    "                \n",
    "            entity_type = entity.get('type', 'unknown')\n",
    "            spans = entity.get('span', [])\n",
    "            \n",
    "            if not spans:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            entity_token_indices = set()\n",
    "            for char_pos in spans:\n",
    "                if char_pos in char_to_token:\n",
    "                    entity_token_indices.add(char_to_token[char_pos])\n",
    "            \n",
    "            entity_token_indices = sorted(entity_token_indices)\n",
    "            \n",
    "            if entity_token_indices:\n",
    "                \n",
    "                b_tag = f\"B-{entity_type}\"\n",
    "                i_tag = f\"I-{entity_type}\"\n",
    "                \n",
    "                if b_tag in self.vocabs['slot'] and i_tag in self.vocabs['slot']:\n",
    "                   \n",
    "                    slot_labels[entity_token_indices[0]] = self.vocabs['slot'][b_tag]\n",
    "                   \n",
    "                    for j in range(1, len(entity_token_indices)):\n",
    "                        slot_labels[entity_token_indices[j]] = self.vocabs['slot'][i_tag]\n",
    "        \n",
    "        return {\n",
    "            \"tokens\": torch.LongTensor(tokens), \n",
    "            \"intent\": intent_label, \n",
    "            \"slots\": torch.LongTensor(slot_labels)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All five LSTM model architectures are defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class IntentClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, intent_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size + 10, emb_dim, padding_idx=0) \n",
    "        self.recurrent_layer = ScratchLSTM(emb_dim, hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, intent_size)\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        \n",
    "        tokens = torch.clamp(tokens, 0, self.embedding.num_embeddings - 1)\n",
    "        embedded = self.embedding(tokens)\n",
    "        _, (hidden, _) = self.recurrent_layer(embedded)\n",
    "        hidden = torch.cat((hidden[0], hidden[1]), dim=1)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "class SlotFiller(nn.Module):\n",
    "    def __init__(self, vocab_size, slot_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.embedding = nn.Embedding(vocab_size + 10, emb_dim, padding_idx=0)  \n",
    "        self.recurrent_layer = ScratchLSTM(emb_dim, hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, slot_size)\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        \n",
    "        tokens = torch.clamp(tokens, 0, self.embedding.num_embeddings - 1)\n",
    "        embedded = self.embedding(tokens)\n",
    "        recurrent_out, _ = self.recurrent_layer(embedded)\n",
    "        return self.fc(recurrent_out)\n",
    "\n",
    "class IntentClassifierWithSlots(nn.Module):\n",
    "    def __init__(self, vocab_size, intent_size, slot_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size + 10, emb_dim, padding_idx=0)\n",
    "        self.slot_embedding = nn.Embedding(slot_size, emb_dim // 2, padding_idx=0)\n",
    "        self.recurrent_layer = ScratchLSTM(emb_dim + emb_dim // 2, hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, intent_size)\n",
    "        \n",
    "    def forward(self, tokens, predicted_slots):\n",
    "        tokens = torch.clamp(tokens, 0, self.word_embedding.num_embeddings - 1)\n",
    "        predicted_slots = torch.clamp(predicted_slots, 0, self.slot_embedding.num_embeddings - 1)\n",
    "        \n",
    "        word_embedded = self.word_embedding(tokens)\n",
    "        slot_embedded = self.slot_embedding(predicted_slots)\n",
    "        combined_embedded = torch.cat((word_embedded, slot_embedded), dim=2)\n",
    "        _, (hidden, _) = self.recurrent_layer(combined_embedded)\n",
    "        hidden = torch.cat((hidden[0], hidden[1]), dim=1)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "class SlotFillerWithIntent(nn.Module):\n",
    "    def __init__(self, vocab_size, intent_size, slot_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding(vocab_size + 10, emb_dim, padding_idx=0)\n",
    "        self.intent_embedding = nn.Embedding(intent_size, emb_dim // 4)\n",
    "        self.recurrent_layer = ScratchLSTM(emb_dim + emb_dim // 4, hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, slot_size)\n",
    "        \n",
    "    def forward(self, tokens, predicted_intent):\n",
    "        tokens = torch.clamp(tokens, 0, self.word_embedding.num_embeddings - 1)\n",
    "        predicted_intent = torch.clamp(predicted_intent, 0, self.intent_embedding.num_embeddings - 1)\n",
    "        \n",
    "        word_embedded = self.word_embedding(tokens)\n",
    "        intent_embedded = self.intent_embedding(predicted_intent).unsqueeze(1)\n",
    "        intent_embedded = intent_embedded.expand(-1, tokens.shape[1], -1)\n",
    "        combined_embedded = torch.cat((word_embedded, intent_embedded), dim=2)\n",
    "        recurrent_out, _ = self.recurrent_layer(combined_embedded)\n",
    "        return self.fc(recurrent_out)\n",
    "\n",
    "class JointModel(nn.Module):\n",
    "    def __init__(self, vocab_size, intent_size, slot_size, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 10, emb_dim, padding_idx=0)\n",
    "        self.recurrent_layer = ScratchLSTM(emb_dim, hidden_dim, bidirectional=True)\n",
    "        self.intent_fc = nn.Linear(hidden_dim * 2, intent_size)\n",
    "        self.slot_fc = nn.Linear(hidden_dim * 2, slot_size)\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        tokens = torch.clamp(tokens, 0, self.embedding.num_embeddings - 1)\n",
    "        embedded = self.embedding(tokens)\n",
    "        recurrent_out, (hidden, _) = self.recurrent_layer(embedded)\n",
    "        final_hidden = torch.cat((hidden[0], hidden[1]), dim=1)\n",
    "        return self.intent_fc(final_hidden), self.slot_fc(recurrent_out)\n",
    "\n",
    "print(\"All five LSTM model architectures are defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_fixed(model, loader, model_type, best_slot_model=None, best_intent_model=None):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if model_type == \"intent\":\n",
    "            all_preds, all_true = [], []\n",
    "            for batch in loader:\n",
    "                outputs = model(batch['tokens'].to(Config.DEVICE))\n",
    "                all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "                all_true.extend(batch['intents'].numpy())\n",
    "            \n",
    "            if all_true:\n",
    "                report = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "                results['intent_accuracy'] = accuracy_score(all_true, all_preds)\n",
    "                results['intent_f1_macro'] = report['macro avg']['f1-score']\n",
    "                results['intent_f1_weighted'] = report['weighted avg']['f1-score']\n",
    "        \n",
    "        elif model_type == \"slot_to_intent\":\n",
    "            all_preds, all_true = [], []\n",
    "            for batch in loader:\n",
    "                tokens = batch['tokens'].to(Config.DEVICE)\n",
    "                predicted_slots = torch.argmax(best_slot_model(tokens), dim=2)\n",
    "                outputs = model(tokens, predicted_slots)\n",
    "                all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "                all_true.extend(batch['intents'].numpy())\n",
    "            \n",
    "            if all_true:\n",
    "                report = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "                results['intent_accuracy'] = accuracy_score(all_true, all_preds)\n",
    "                results['intent_f1_macro'] = report['macro avg']['f1-score']\n",
    "                results['intent_f1_weighted'] = report['weighted avg']['f1-score']\n",
    "\n",
    "        elif model_type == \"slot\" or model_type == \"intent_to_slot\":\n",
    "            all_preds, all_true = [], []\n",
    "            slot_distribution = Counter()\n",
    "            non_o_predictions = 0\n",
    "            total_predictions = 0\n",
    "            \n",
    "            for batch in loader:\n",
    "                tokens = batch['tokens'].to(Config.DEVICE)\n",
    "                slots_true_np = batch['slots'].numpy()\n",
    "                \n",
    "                if model_type == \"intent_to_slot\":\n",
    "                    predicted_intent = torch.argmax(best_intent_model(tokens), dim=1)\n",
    "                    outputs = model(tokens, predicted_intent)\n",
    "                else:\n",
    "                    outputs = model(tokens)\n",
    "                    \n",
    "                slot_preds = torch.argmax(outputs, dim=2).cpu().numpy()\n",
    "                \n",
    "                for i in range(slots_true_np.shape[0]):\n",
    "                    for j in range(slots_true_np.shape[1]):\n",
    "                        if slots_true_np[i, j] != 0:  \n",
    "                            all_preds.append(slot_preds[i, j])\n",
    "                            all_true.append(slots_true_np[i, j])\n",
    "                            slot_distribution[slot_preds[i, j]] += 1\n",
    "                            total_predictions += 1\n",
    "                            if slot_preds[i, j] != 0:  \n",
    "                                non_o_predictions += 1\n",
    "            \n",
    "            if all_true:\n",
    "            \n",
    "                print(f\"      Slot Prediction Distribution:\")\n",
    "                for slot_idx, count in slot_distribution.most_common(10):\n",
    "                    slot_name = loader.dataset.vocabs['idx_to_slot'].get(slot_idx, f\"UNK_{slot_idx}\")\n",
    "                    percentage = (count / total_predictions) * 100\n",
    "                    print(f\"        {slot_name}: {count} ({percentage:.1f}%)\")\n",
    "                print(f\"      Non-O predictions: {non_o_predictions}/{total_predictions} ({non_o_predictions/total_predictions*100:.1f}%)\")\n",
    "                \n",
    "                report = classification_report(all_true, all_preds, output_dict=True, zero_division=0)\n",
    "                results['slot_accuracy'] = accuracy_score(all_true, all_preds)\n",
    "                results['slot_f1_macro'] = report['macro avg']['f1-score']\n",
    "                results['slot_f1_weighted'] = report['weighted avg']['f1-score']\n",
    "        \n",
    "        elif model_type == \"joint\":\n",
    "            intent_preds, intent_true, slot_preds, slot_true = [], [], [], []\n",
    "            slot_distribution = Counter()\n",
    "            non_o_predictions = 0\n",
    "            total_predictions = 0\n",
    "            \n",
    "            for batch in loader:\n",
    "                tokens = batch['tokens'].to(Config.DEVICE)\n",
    "                intents_np, slots_np = batch['intents'].numpy(), batch['slots'].numpy()\n",
    "                \n",
    "                intent_logits, slot_logits = model(tokens)\n",
    "                intent_preds.extend(torch.argmax(intent_logits, dim=1).cpu().numpy())\n",
    "                intent_true.extend(intents_np)\n",
    "                \n",
    "                slot_preds_batch = torch.argmax(slot_logits, dim=2).cpu().numpy()\n",
    "                for i in range(slots_np.shape[0]):\n",
    "                    for j in range(slots_np.shape[1]):\n",
    "                        if slots_np[i, j] != 0:  \n",
    "                            slot_preds.append(slot_preds_batch[i, j])\n",
    "                            slot_true.append(slots_np[i, j])\n",
    "                            slot_distribution[slot_preds_batch[i, j]] += 1\n",
    "                            total_predictions += 1\n",
    "                            if slot_preds_batch[i, j] != 0:\n",
    "                                non_o_predictions += 1\n",
    "            \n",
    "            if intent_true:\n",
    "                intent_report = classification_report(intent_true, intent_preds, output_dict=True, zero_division=0)\n",
    "                results['intent_accuracy'] = accuracy_score(intent_true, intent_preds)\n",
    "                results['intent_f1_macro'] = intent_report['macro avg']['f1-score']\n",
    "                results['intent_f1_weighted'] = intent_report['weighted avg']['f1-score']\n",
    "            \n",
    "            if slot_true:\n",
    "                \n",
    "                print(f\"      Joint Model Slot Distribution:\")\n",
    "                for slot_idx, count in slot_distribution.most_common(10):\n",
    "                    slot_name = loader.dataset.vocabs['idx_to_slot'].get(slot_idx, f\"UNK_{slot_idx}\")\n",
    "                    percentage = (count / total_predictions) * 100\n",
    "                    print(f\"        {slot_name}: {count} ({percentage:.1f}%)\")\n",
    "                print(f\"      Non-O predictions: {non_o_predictions}/{total_predictions} ({non_o_predictions/total_predictions*100:.1f}%)\")\n",
    "                \n",
    "                slot_report = classification_report(slot_true, slot_preds, output_dict=True, zero_division=0)\n",
    "                results['slot_accuracy'] = accuracy_score(slot_true, slot_preds)\n",
    "                results['slot_f1_macro'] = slot_report['macro avg']['f1-score']\n",
    "                results['slot_f1_weighted'] = slot_report['weighted avg']['f1-score']\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff48d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated experiment runner for working slot data is defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_all_experiments_working_slots(train_loader, test_loader, vocabs, dataset_name):\n",
    "    print(f\"\\n\" + \"#\"*70)\n",
    "    print(f\"##   RUNNING ALL EXPERIMENTS FOR: LSTM - {dataset_name}   ##\")\n",
    "    print(\"#\"*70 + \"\\n\")\n",
    "\n",
    "    vocab_size = len(vocabs['word'])\n",
    "    intent_size = len(vocabs['intent'])\n",
    "    slot_size = len(vocabs['slot'])\n",
    "    \n",
    "    print(f\"Model Parameters: vocab_size={vocab_size}, intent_size={intent_size}, slot_size={slot_size}\")\n",
    "    \n",
    "    \n",
    "    print(\"Analyzing ACTUAL slot distribution from dataset...\")\n",
    "    actual_slot_counter = Counter()\n",
    "    total_slots = 0\n",
    "    non_o_slots = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        slots = batch['slots']\n",
    "        for i in range(slots.shape[0]):\n",
    "            for j in range(slots.shape[1]):\n",
    "                slot_idx = slots[i, j].item()\n",
    "                if slot_idx != 0: \n",
    "                    actual_slot_counter[slot_idx] += 1\n",
    "                    total_slots += 1\n",
    "                    if slot_idx != vocabs['slot']['O']:\n",
    "                        non_o_slots += 1\n",
    "    \n",
    "    print(\"Top 10 ACTUAL slot types in training data:\")\n",
    "    for slot_idx, count in actual_slot_counter.most_common(10):\n",
    "        slot_name = vocabs['idx_to_slot'].get(slot_idx, f\"UNK_{slot_idx}\")\n",
    "        percentage = (count / total_slots) * 100\n",
    "        print(f\"  {slot_name}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    o_count = actual_slot_counter.get(vocabs['slot']['O'], 0)\n",
    "    print(f\"O vs non-O distribution: O={o_count} ({o_count/total_slots*100:.1f}%), non-O={non_o_slots} ({non_o_slots/total_slots*100:.1f}%)\")\n",
    "    \n",
    "    loss_fn_intent = nn.CrossEntropyLoss()\n",
    "    \n",
    "    slot_weights = torch.ones(slot_size).to(Config.DEVICE)\n",
    "    for slot_idx, count in actual_slot_counter.items():\n",
    "        if count > 0:\n",
    "            \n",
    "            slot_weights[slot_idx] = total_slots / (len(actual_slot_counter) * count)\n",
    "    \n",
    "    print(\"Using class weights for slot filling to handle imbalance\")\n",
    "    loss_fn_slot = nn.CrossEntropyLoss(weight=slot_weights, ignore_index=0)\n",
    "    \n",
    "    all_results = {}\n",
    "\n",
    "   \n",
    "    print(\"\\n EXPERIMENT 1: Independent Models\")\n",
    "    intent_model = IntentClassifier(vocab_size, intent_size, Config.EMBEDDING_DIM, Config.HIDDEN_DIM).to(Config.DEVICE)\n",
    "    slot_model = SlotFiller(vocab_size, slot_size, Config.EMBEDDING_DIM, Config.HIDDEN_DIM).to(Config.DEVICE)\n",
    "    \n",
    "   \n",
    "    print(\"  Training Intent Model...\")\n",
    "    optimizer = torch.optim.Adam(intent_model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        intent_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            tokens = batch['tokens'].to(Config.DEVICE)\n",
    "            intents = batch['intents'].to(Config.DEVICE)\n",
    "            \n",
    "            outputs = intent_model(tokens)\n",
    "            loss = loss_fn_intent(outputs, intents)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"    [Intent] Epoch {epoch+1}/{Config.NUM_EPOCHS}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    \n",
    "    print(\"  Training Slot Model...\")\n",
    "    optimizer = torch.optim.Adam(slot_model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        slot_model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            tokens = batch['tokens'].to(Config.DEVICE)\n",
    "            slots = batch['slots'].to(Config.DEVICE)\n",
    "            \n",
    "            outputs = slot_model(tokens)\n",
    "            \n",
    "            \n",
    "            batch_size, seq_len = slots.shape\n",
    "            outputs_flat = outputs.contiguous().view(batch_size * seq_len, -1)\n",
    "            slots_flat = slots.contiguous().view(-1)\n",
    "            \n",
    "            loss = loss_fn_slot(outputs_flat, slots_flat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "        avg_loss = total_loss / batch_count\n",
    "        \n",
    "       \n",
    "        print(f\"    [Slot]   Epoch {epoch+1}/{Config.NUM_EPOCHS}, Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        if (epoch + 1) % 3 == 0 or epoch + 1 == Config.NUM_EPOCHS:\n",
    "            slot_model.eval()\n",
    "            with torch.no_grad():\n",
    "                sample_batch = next(iter(train_loader))\n",
    "                sample_tokens = sample_batch['tokens'][:1].to(Config.DEVICE)\n",
    "                sample_slots = sample_batch['slots'][:1]\n",
    "                sample_outputs = slot_model(sample_tokens)\n",
    "                sample_preds = torch.argmax(sample_outputs, dim=2).cpu()\n",
    "                \n",
    "                g\n",
    "                idx_to_word = {idx: word for word, idx in vocabs['word'].items()}\n",
    "                \n",
    "                \n",
    "                sample_token_indices = sample_tokens[0].cpu()\n",
    "                sample_words = []\n",
    "                for idx in sample_token_indices:\n",
    "                    if idx == 0:  \n",
    "                        break\n",
    "                    sample_words.append(idx_to_word.get(idx.item(), f\"UNK_{idx.item()}\"))\n",
    "                \n",
    "                print(f\"      Sample prediction:\")\n",
    "                print(f\"        Text: {' '.join(sample_words)}\")\n",
    "                \n",
    "                \n",
    "                true_slots = []\n",
    "                pred_slots = []\n",
    "                for i in range(min(len(sample_words), sample_slots.shape[1])):\n",
    "                    true_idx = sample_slots[0, i].item()\n",
    "                    pred_idx = sample_preds[0, i].item()\n",
    "                    if true_idx != 0: \n",
    "                        true_slots.append(vocabs['idx_to_slot'].get(true_idx, f\"UNK_{true_idx}\"))\n",
    "                        pred_slots.append(vocabs['idx_to_slot'].get(pred_idx, f\"UNK_{pred_idx}\"))\n",
    "                \n",
    "                print(f\"        True:  {true_slots}\")\n",
    "                print(f\"        Pred:  {pred_slots}\")\n",
    "                \n",
    "                \n",
    "                unique_preds = set(pred_slots)\n",
    "                o_count = pred_slots.count('O')\n",
    "                total_count = len(pred_slots)\n",
    "                if total_count > 0:\n",
    "                    o_percentage = (o_count / total_count) * 100\n",
    "                    print(f\"        Unique predictions: {unique_preds}\")\n",
    "                    print(f\"        'O' predictions: {o_count}/{total_count} ({o_percentage:.1f}%)\")\n",
    "            \n",
    "            slot_model.train()\n",
    "    \n",
    "    \n",
    "    best_intent_model = copy.deepcopy(intent_model)\n",
    "    best_slot_model = copy.deepcopy(slot_model)\n",
    "    \n",
    "    print(\"  Evaluating Independent Models...\")\n",
    "    intent_results = evaluate_fixed(intent_model, test_loader, \"intent\")\n",
    "    slot_results = evaluate_fixed(slot_model, test_loader, \"slot\")\n",
    "    all_results['Independent'] = {**intent_results, **slot_results}\n",
    "\n",
    "    \n",
    "    print(\"\\nüöÄ EXPERIMENT 2: Slot -> Intent Pipeline\")\n",
    "    pipeline_model = IntentClassifierWithSlots(vocab_size, intent_size, slot_size, Config.EMBEDDING_DIM, Config.HIDDEN_DIM).to(Config.DEVICE)\n",
    "    optimizer = torch.optim.Adam(pipeline_model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        pipeline_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            tokens = batch['tokens'].to(Config.DEVICE)\n",
    "            intents = batch['intents'].to(Config.DEVICE)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predicted_slots = torch.argmax(best_slot_model(tokens), dim=2)\n",
    "            \n",
    "            outputs = pipeline_model(tokens, predicted_slots)\n",
    "            loss = loss_fn_intent(outputs, intents)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"    [S->I]   Epoch {epoch+1}/{Config.NUM_EPOCHS}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    all_results['Slot -> Intent'] = evaluate_fixed(pipeline_model, test_loader, \"slot_to_intent\", best_slot_model=best_slot_model)\n",
    "\n",
    "    \n",
    "    print(\"\\nüöÄ EXPERIMENT 3: Intent -> Slot Pipeline\")\n",
    "    pipeline_model = SlotFillerWithIntent(vocab_size, intent_size, slot_size, Config.EMBEDDING_DIM, Config.HIDDEN_DIM).to(Config.DEVICE)\n",
    "    optimizer = torch.optim.Adam(pipeline_model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        pipeline_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            tokens = batch['tokens'].to(Config.DEVICE)\n",
    "            slots = batch['slots'].to(Config.DEVICE)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predicted_intent = torch.argmax(best_intent_model(tokens), dim=1)\n",
    "            \n",
    "            outputs = pipeline_model(tokens, predicted_intent)\n",
    "            \n",
    "            batch_size, seq_len = slots.shape\n",
    "            outputs_flat = outputs.contiguous().view(batch_size * seq_len, -1)\n",
    "            slots_flat = slots.contiguous().view(-1)\n",
    "            \n",
    "            loss = loss_fn_slot(outputs_flat, slots_flat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"    [I->S]   Epoch {epoch+1}/{Config.NUM_EPOCHS}, Loss: {total_loss/len(train_loader):.6f}\")\n",
    "    \n",
    "    all_results['Intent -> Slot'] = evaluate_fixed(pipeline_model, test_loader, \"intent_to_slot\", best_intent_model=best_intent_model)\n",
    "\n",
    "    \n",
    "    print(\"\\nüöÄ EXPERIMENT 4: Joint Model (Multi-Task)\")\n",
    "    joint_model = JointModel(vocab_size, intent_size, slot_size, Config.EMBEDDING_DIM, Config.HIDDEN_DIM).to(Config.DEVICE)\n",
    "    optimizer = torch.optim.Adam(joint_model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        joint_model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            tokens = batch['tokens'].to(Config.DEVICE)\n",
    "            intents = batch['intents'].to(Config.DEVICE)\n",
    "            slots = batch['slots'].to(Config.DEVICE)\n",
    "            \n",
    "            intent_logits, slot_logits = joint_model(tokens)\n",
    "            \n",
    "            loss_intent = loss_fn_intent(intent_logits, intents)\n",
    "            \n",
    "            batch_size, seq_len = slots.shape\n",
    "            slot_logits_flat = slot_logits.contiguous().view(batch_size * seq_len, -1)\n",
    "            slots_flat = slots.contiguous().view(-1)\n",
    "            loss_slot = loss_fn_slot(slot_logits_flat, slots_flat)\n",
    "            \n",
    "            loss = loss_intent + loss_slot\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"    [Joint]  Epoch {epoch+1}/{Config.NUM_EPOCHS}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    all_results['Joint'] = evaluate_fixed(joint_model, test_loader, \"joint\")\n",
    "\n",
    "    \n",
    "    print_results_table(all_results, dataset_name)\n",
    "    return all_results\n",
    "\n",
    "print(\"Updated experiment runner for working slot data is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a9ff8",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING ACTUAL SLURP DATASET EXPERIMENTS (FIXED SPAN ALIGNMENT)\n",
      "================================================================================\n",
      "Loading ACTUAL SLURP dataset with working span alignment...\n",
      "ACTUAL SLURP Dataset: 11514 train, 2974 test examples\n",
      "Building vocabulary from ACTUAL SLURP data...\n",
      "ACTUAL SLURP Vocab: 6069 words, 60 intents, 111 slots\n",
      "ACTUAL SLURP - Train batches: 360, Test batches: 93\n",
      "\n",
      "üîç DEBUGGING ENTITY ALIGNMENT IN ACTUAL SLURP:\n",
      "\n",
      "Example 2 with entities:\n",
      "  Sentence: 'i need an event three days from now scheduled with amy'\n",
      "  Intent: calendar_set\n",
      "  Entity 1: type='date', span=[4, 5, 6, 7]\n",
      "  Entity 2: type='person', span=[10]\n",
      "  Tokens: ['i', 'need', 'an', 'event', 'three', 'days', 'from', 'now', 'scheduled', 'with', 'amy']\n",
      "  Slots:  ['O', 'B-date', 'I-date', 'B-person', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "  ‚úÖ SUCCESS: Found 3 non-O slots: ['B-date', 'I-date', 'B-person']\n",
      "\n",
      "Example 7 with entities:\n",
      "  Sentence: 'silent mode on for the next three hours'\n",
      "  Intent: audio_volume_mute\n",
      "  Entity 1: type='time', span=[5, 6, 7]\n",
      "  Tokens: ['silent', 'mode', 'on', 'for', 'the', 'next', 'three', 'hours']\n",
      "  Slots:  ['B-time', 'I-time', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "  ‚úÖ SUCCESS: Found 2 non-O slots: ['B-time', 'I-time']\n",
      "\n",
      "Example 8 with entities:\n",
      "  Sentence: 'remove dog food from my grocery list'\n",
      "  Intent: lists_remove\n",
      "  Entity 1: type='list_name', span=[5, 6]\n",
      "  Tokens: ['remove', 'dog', 'food', 'from', 'my', 'grocery', 'list']\n",
      "  Slots:  ['B-list_name', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "  ‚úÖ SUCCESS: Found 1 non-O slots: ['B-list_name']\n",
      "\n",
      "üìä ANALYZING SLOT DISTRIBUTION FROM ACTUAL SLURP:\n",
      "Top 15 slot types from ACTUAL SLURP:\n",
      "  O: 69901 (88.4%)\n",
      "  B-date: 1379 (1.7%)\n",
      "  B-place_name: 884 (1.1%)\n",
      "  B-person: 695 (0.9%)\n",
      "  B-time: 674 (0.9%)\n",
      "  B-event_name: 645 (0.8%)\n",
      "  B-media_type: 343 (0.4%)\n",
      "  B-business_name: 318 (0.4%)\n",
      "  B-food_type: 217 (0.3%)\n",
      "  B-transport_type: 213 (0.3%)\n",
      "  B-device_type: 210 (0.3%)\n",
      "  B-definition_word: 206 (0.3%)\n",
      "  B-artist_name: 195 (0.2%)\n",
      "  B-weather_descriptor: 179 (0.2%)\n",
      "  B-relation: 178 (0.2%)\n",
      "O vs non-O distribution: O=69901 (88.4%), non-O=9150 (11.6%)\n",
      "\n",
      "‚úÖ SUCCESS: Found meaningful non-O slots (11.6%) in ACTUAL SLURP!\n",
      "üöÄ Running all 4 LSTM experiments on ACTUAL SLURP data...\n",
      "\n",
      "######################################################################\n",
      "##   RUNNING ALL EXPERIMENTS FOR: LSTM - ACTUAL SLURP   ##\n",
      "######################################################################\n",
      "\n",
      "Model Parameters: vocab_size=6069, intent_size=60, slot_size=111\n",
      "Analyzing ACTUAL slot distribution from dataset...\n",
      "Top 10 ACTUAL slot types in training data:\n",
      "  O: 69901 (88.4%)\n",
      "  B-date: 1379 (1.7%)\n",
      "  B-place_name: 884 (1.1%)\n",
      "  B-person: 695 (0.9%)\n",
      "  B-time: 674 (0.9%)\n",
      "  B-event_name: 645 (0.8%)\n",
      "  B-media_type: 343 (0.4%)\n",
      "  B-business_name: 318 (0.4%)\n",
      "  B-food_type: 217 (0.3%)\n",
      "  B-transport_type: 213 (0.3%)\n",
      "O vs non-O distribution: O=69901 (88.4%), non-O=9150 (11.6%)\n",
      "Using class weights for slot filling to handle imbalance\n",
      "\n",
      "üöÄ EXPERIMENT 1: Independent Models\n",
      "  Training Intent Model...\n",
      "    [Intent] Epoch 2/10, Loss: 1.1587\n",
      "    [Intent] Epoch 4/10, Loss: 0.5285\n",
      "    [Intent] Epoch 6/10, Loss: 0.2642\n",
      "    [Intent] Epoch 8/10, Loss: 0.1286\n",
      "    [Intent] Epoch 10/10, Loss: 0.0647\n",
      "  Training Slot Model...\n",
      "    [Slot]   Epoch 1/10, Loss: 4.101424\n",
      "    [Slot]   Epoch 2/10, Loss: 2.693341\n",
      "    [Slot]   Epoch 3/10, Loss: 1.753127\n",
      "      Sample prediction:\n",
      "        Text: vacuum the living room carpet\n",
      "        True:  ['B-house_place', 'O', 'O', 'O', 'O']\n",
      "        Pred:  ['B-house_place', 'B-house_place', 'B-house_place', 'B-house_place', 'O']\n",
      "        Unique predictions: {'O', 'B-house_place'}\n",
      "        'O' predictions: 1/5 (20.0%)\n",
      "    [Slot]   Epoch 4/10, Loss: 1.144487\n",
      "    [Slot]   Epoch 5/10, Loss: 0.826660\n",
      "    [Slot]   Epoch 6/10, Loss: 0.601110\n",
      "      Sample prediction:\n",
      "        Text: when last did i receive a new email\n",
      "        True:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "        Pred:  ['B-person', 'B-person', 'B-person', 'O', 'O', 'O', 'O', 'O']\n",
      "        Unique predictions: {'O', 'B-person'}\n",
      "        'O' predictions: 5/8 (62.5%)\n",
      "    [Slot]   Epoch 7/10, Loss: 0.468815\n",
      "    [Slot]   Epoch 8/10, Loss: 0.372844\n",
      "    [Slot]   Epoch 9/10, Loss: 0.297887\n",
      "      Sample prediction:\n",
      "        Text: tell me present time in malaysia\n",
      "        True:  ['O', 'B-place_name', 'O', 'O', 'O', 'O']\n",
      "        Pred:  ['B-place_name', 'B-place_name', 'B-place_name', 'B-place_name', 'O', 'O']\n",
      "        Unique predictions: {'B-place_name', 'O'}\n",
      "        'O' predictions: 2/6 (33.3%)\n",
      "    [Slot]   Epoch 10/10, Loss: 0.238068\n",
      "      Sample prediction:\n",
      "        Text: headlines from dhaka tribune\n",
      "        True:  ['B-media_type', 'O', 'O', 'O']\n",
      "        Pred:  ['B-media_type', 'B-person', 'O', 'O']\n",
      "        Unique predictions: {'O', 'B-media_type', 'B-person'}\n",
      "        'O' predictions: 2/4 (50.0%)\n",
      "  Evaluating Independent Models...\n",
      "      Slot Prediction Distribution:\n",
      "        O: 12263 (60.9%)\n",
      "        B-person: 659 (3.3%)\n",
      "        B-place_name: 549 (2.7%)\n",
      "        B-date: 476 (2.4%)\n",
      "        B-event_name: 447 (2.2%)\n",
      "        B-time: 372 (1.8%)\n",
      "        B-media_type: 295 (1.5%)\n",
      "        B-list_name: 274 (1.4%)\n",
      "        B-business_name: 250 (1.2%)\n",
      "        B-weather_descriptor: 226 (1.1%)\n",
      "      Non-O predictions: 20137/20137 (100.0%)\n",
      "\n",
      "üöÄ EXPERIMENT 2: Slot -> Intent Pipeline\n",
      "    [S->I]   Epoch 2/10, Loss: 0.9894\n",
      "    [S->I]   Epoch 4/10, Loss: 0.5134\n",
      "    [S->I]   Epoch 6/10, Loss: 0.2635\n",
      "    [S->I]   Epoch 8/10, Loss: 0.1235\n",
      "    [S->I]   Epoch 10/10, Loss: 0.0562\n",
      "\n",
      "üöÄ EXPERIMENT 3: Intent -> Slot Pipeline\n",
      "    [I->S]   Epoch 2/10, Loss: 1.865502\n",
      "    [I->S]   Epoch 4/10, Loss: 1.101707\n",
      "    [I->S]   Epoch 6/10, Loss: 0.701363\n",
      "    [I->S]   Epoch 8/10, Loss: 0.460127\n",
      "    [I->S]   Epoch 10/10, Loss: 0.324262\n",
      "      Slot Prediction Distribution:\n",
      "        O: 11402 (56.6%)\n",
      "        B-place_name: 660 (3.3%)\n",
      "        B-person: 633 (3.1%)\n",
      "        B-event_name: 461 (2.3%)\n",
      "        B-date: 401 (2.0%)\n",
      "        B-time: 399 (2.0%)\n",
      "        B-list_name: 345 (1.7%)\n",
      "        B-media_type: 264 (1.3%)\n",
      "        B-artist_name: 239 (1.2%)\n",
      "        B-news_topic: 234 (1.2%)\n",
      "      Non-O predictions: 20137/20137 (100.0%)\n",
      "\n",
      "üöÄ EXPERIMENT 4: Joint Model (Multi-Task)\n",
      "    [Joint]  Epoch 2/10, Loss: 4.0277\n",
      "    [Joint]  Epoch 4/10, Loss: 1.9021\n",
      "    [Joint]  Epoch 6/10, Loss: 1.0563\n",
      "    [Joint]  Epoch 8/10, Loss: 0.6729\n",
      "    [Joint]  Epoch 10/10, Loss: 0.4367\n",
      "      Joint Model Slot Distribution:\n",
      "        O: 11589 (57.6%)\n",
      "        B-date: 722 (3.6%)\n",
      "        B-person: 634 (3.1%)\n",
      "        B-place_name: 579 (2.9%)\n",
      "        B-time: 530 (2.6%)\n",
      "        B-event_name: 465 (2.3%)\n",
      "        B-list_name: 329 (1.6%)\n",
      "        B-food_type: 278 (1.4%)\n",
      "        B-media_type: 270 (1.3%)\n",
      "        B-artist_name: 237 (1.2%)\n",
      "      Non-O predictions: 20137/20137 (100.0%)\n",
      "\n",
      "====================================================================================================\n",
      "‚úÖ FINAL RESULTS SUMMARY (LSTM) - ACTUAL SLURP\n",
      "====================================================================================================\n",
      "Experiment           | Intent Acc | Intent F1-M | Intent F1-W | Slot Acc   | Slot F1-M  | Slot F1-W \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Independent          | 0.7872     | 0.7443     | 0.7873     | 0.6699     | 0.1616     | 0.7497    \n",
      "Slot -> Intent       | 0.7888     | 0.7563     | 0.7896     | N/A        | N/A        | N/A       \n",
      "Intent -> Slot       | N/A        | N/A        | N/A        | 0.6237     | 0.1461     | 0.7163    \n",
      "Joint                | 0.7784     | 0.7199     | 0.7768     | 0.6369     | 0.1641     | 0.7240    \n",
      "====================================================================================================\n",
      "\n",
      "‚ú® ACTUAL SLURP DATASET EXPERIMENTS COMPLETED SUCCESSFULLY! ‚ú®\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*80)\n",
    "    print(\"STARTING ACTUAL SLURP DATASET EXPERIMENTS (FIXED SPAN ALIGNMENT)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        slurp_train_data, slurp_test_data, slurp_vocabs = load_actual_slurp_data_fixed()\n",
    "        \n",
    "       \n",
    "        slurp_train_dataset = FixedActualSLURPDataset(slurp_train_data, slurp_vocabs)\n",
    "        slurp_test_dataset = FixedActualSLURPDataset(slurp_test_data, slurp_vocabs)\n",
    "        \n",
    "        \n",
    "        slurp_train_loader = DataLoader(slurp_train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, \n",
    "                                       collate_fn=collate_fn_factory(slurp_vocabs))\n",
    "        slurp_test_loader = DataLoader(slurp_test_dataset, batch_size=Config.BATCH_SIZE, \n",
    "                                      collate_fn=collate_fn_factory(slurp_vocabs))\n",
    "        \n",
    "        print(f\"ACTUAL SLURP - Train batches: {len(slurp_train_loader)}, Test batches: {len(slurp_test_loader)}\")\n",
    "        \n",
    "        \n",
    "        print(\"\\nüîç DEBUGGING ENTITY ALIGNMENT IN ACTUAL SLURP:\")\n",
    "        entity_examples_found = 0\n",
    "        \n",
    "        for i in range(min(20, len(slurp_train_data))):\n",
    "            item = slurp_train_data[i]\n",
    "            entities = item.get('entities', [])\n",
    "            \n",
    "            if entities:\n",
    "                entity_examples_found += 1\n",
    "                print(f\"\\nExample {i+1} with entities:\")\n",
    "                print(f\"  Sentence: '{item['sentence']}'\")\n",
    "                print(f\"  Intent: {item['scenario']}_{item['action']}\")\n",
    "                \n",
    "                \n",
    "                for j, entity in enumerate(entities):\n",
    "                    print(f\"  Entity {j+1}: type='{entity.get('type')}', span={entity.get('span', [])}\")\n",
    "                \n",
    "                \n",
    "                sample_item = slurp_train_dataset[i]\n",
    "                idx_to_word = {idx: word for word, idx in slurp_vocabs['word'].items()}\n",
    "                tokens = [idx_to_word.get(idx, 'UNK') for idx in sample_item['tokens'].tolist() if idx != 0]\n",
    "                slots = [slurp_vocabs['idx_to_slot'].get(idx, 'O') for idx in sample_item['slots'].tolist()[:len(tokens)]]\n",
    "                \n",
    "                print(f\"  Tokens: {tokens}\")\n",
    "                print(f\"  Slots:  {slots}\")\n",
    "                \n",
    "                \n",
    "                non_o_slots = [s for s in slots if s != 'O']\n",
    "                if non_o_slots:\n",
    "                    print(f\"  SUCCESS: Found {len(non_o_slots)} non-O slots: {non_o_slots}\")\n",
    "                else:\n",
    "                    print(f\"   PROBLEM: All slots are 'O'\")\n",
    "                \n",
    "                if entity_examples_found >= 3:  \n",
    "                    break\n",
    "        \n",
    "        \n",
    "        print(\"\\n ANALYZING SLOT DISTRIBUTION FROM ACTUAL SLURP:\")\n",
    "        slot_counter = Counter()\n",
    "        total_slots = 0\n",
    "        non_o_slots = 0\n",
    "        \n",
    "        for batch in slurp_train_loader:\n",
    "            slots = batch['slots']\n",
    "            for i in range(slots.shape[0]):\n",
    "                for j in range(slots.shape[1]):\n",
    "                    slot_idx = slots[i, j].item()\n",
    "                    if slot_idx != 0:  \n",
    "                        slot_counter[slot_idx] += 1\n",
    "                        total_slots += 1\n",
    "                        if slot_idx != slurp_vocabs['slot']['O']:\n",
    "                            non_o_slots += 1\n",
    "        \n",
    "        print(\"Top 15 slot types from ACTUAL SLURP:\")\n",
    "        for slot_idx, count in slot_counter.most_common(15):\n",
    "            slot_name = slurp_vocabs['idx_to_slot'].get(slot_idx, f\"UNK_{slot_idx}\")\n",
    "            percentage = (count / total_slots) * 100 if total_slots > 0 else 0\n",
    "            print(f\"  {slot_name}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        o_count = slot_counter.get(slurp_vocabs['slot']['O'], 0)\n",
    "        o_percentage = (o_count / total_slots) * 100 if total_slots > 0 else 0\n",
    "        non_o_percentage = (non_o_slots / total_slots) * 100 if total_slots > 0 else 0\n",
    "        \n",
    "        print(f\"O vs non-O distribution: O={o_count} ({o_percentage:.1f}%), non-O={non_o_slots} ({non_o_percentage:.1f}%)\")\n",
    "        \n",
    "        \n",
    "        if non_o_slots > 0 and non_o_percentage > 5:  \n",
    "            print(f\"\\n SUCCESS: Found meaningful non-O slots ({non_o_percentage:.1f}%) in ACTUAL SLURP!\")\n",
    "            print(\" Running all 4 LSTM experiments on ACTUAL SLURP data...\")\n",
    "            slurp_results = run_all_experiments_working_slots(slurp_train_loader, slurp_test_loader, slurp_vocabs, \"ACTUAL SLURP\")\n",
    "            print(\"\\n ACTUAL SLURP DATASET EXPERIMENTS COMPLETED SUCCESSFULLY! ‚ú®\")\n",
    "        else:\n",
    "            print(f\"\\n PROBLEM: Insufficient non-O slots ({non_o_percentage:.1f}%) in ACTUAL SLURP\")\n",
    "            print(\"The span alignment might still need adjustment.\")\n",
    "            \n",
    "            \n",
    "            print(\"\\nüîß ADDITIONAL SPAN DEBUGGING:\")\n",
    "            for i, item in enumerate(slurp_train_data[:5]):\n",
    "                if item.get('entities'):\n",
    "                    print(f\"\\nDebug Example {i+1}:\")\n",
    "                    print(f\"  Sentence: '{item['sentence']}'\")\n",
    "                    print(f\"  Sentence length: {len(item['sentence'])}\")\n",
    "                    \n",
    "                    \n",
    "                    print(f\"  Character positions (first 50):\")\n",
    "                    for j in range(min(50, len(item['sentence']))):\n",
    "                        print(f\"    {j}: '{item['sentence'][j]}'\")\n",
    "                    \n",
    "                    entities = item.get('entities', [])\n",
    "                    for j, entity in enumerate(entities):\n",
    "                        spans = entity.get('span', [])\n",
    "                        print(f\"  Entity {j+1}: type='{entity.get('type')}', spans={spans}\")\n",
    "                        if spans:\n",
    "                            print(f\"    Span characters: {[item['sentence'][s] if s < len(item['sentence']) else 'OUT_OF_RANGE' for s in spans]}\")\n",
    "                    break\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with ACTUAL SLURP dataset: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a22ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to compare models! Run one of these:\n",
      "1. compare_all_models() - Full evaluation (needs test data)\n",
      "2. show_model_performance() - Quick summary\n",
      "3. quick_model_test() - Test with examples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compare_all_models():\n",
    "    \n",
    "    print(\" MODEL COMPARISON DASHBOARD\")\n",
    "    \n",
    "   \n",
    "    results = {}\n",
    "    \n",
    "    \n",
    "    print(\"\\n ATIS DATASET MODELS\")\n",
    "    \n",
    "    \n",
    "    if os.path.exists(\"saved_models/intent_model.pth\"):\n",
    "        try:\n",
    "            model = load_model_for_inference(\"saved_models/intent_model.pth\", \"intent\", atis_vocabs)\n",
    "            test_results = evaluate_fixed(model, atis_test_loader, \"intent\")\n",
    "            results['ATIS_Intent_Independent'] = test_results\n",
    "            print(f\" Intent Model: {test_results.get('intent_accuracy', 0):.4f} accuracy\")\n",
    "        except Exception as e:\n",
    "            print(f\" ATIS Intent Model: Error - {e}\")\n",
    "    \n",
    "    if os.path.exists(\"saved_models/slot_model.pth\"):\n",
    "        try:\n",
    "            model = load_model_for_inference(\"saved_models/slot_model.pth\", \"slot\", atis_vocabs)\n",
    "            test_results = evaluate_fixed(model, atis_test_loader, \"slot\")\n",
    "            results['ATIS_Slot_Independent'] = test_results\n",
    "            print(f\"Slot Model: {test_results.get('slot_accuracy', 0):.4f} accuracy\")\n",
    "        except Exception as e:\n",
    "            print(f\" ATIS Slot Model: Error - {e}\")\n",
    "    \n",
    "    if os.path.exists(\"saved_models/joint_model.pth\"):\n",
    "        try:\n",
    "            model = load_model_for_inference(\"saved_models/joint_model.pth\", \"joint\", atis_vocabs)\n",
    "            test_results = evaluate_fixed(model, atis_test_loader, \"joint\")\n",
    "            results['ATIS_Joint'] = test_results\n",
    "            print(f\"Joint Model: Intent={test_results.get('intent_accuracy', 0):.4f}, Slot={test_results.get('slot_accuracy', 0):.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\" ATIS Joint Model: Error - {e}\")\n",
    "    \n",
    "    \n",
    "    print(\"\\n SLURP DATASET MODELS\")\n",
    "    \n",
    "    \n",
    "    if os.path.exists(\"saved_models/slurp_intent_classifier.pth\"):\n",
    "        try:\n",
    "            model = load_slurp_intent_model(\"saved_models/slurp_intent_classifier.pth\", slurp_vocabs)\n",
    "            test_results = evaluate_fixed(model, slurp_test_loader, \"intent\")\n",
    "            results['SLURP_Intent_Independent'] = test_results\n",
    "            print(f\" Intent Model: {test_results.get('intent_accuracy', 0):.4f} accuracy\")\n",
    "        except Exception as e:\n",
    "            print(f\" SLURP Intent Model: Error - {e}\")\n",
    "    \n",
    "    if os.path.exists(\"saved_models/slurp_slot_filler.pth\"):\n",
    "        try:\n",
    "            model = load_slurp_slot_model(\"saved_models/slurp_slot_filler.pth\", slurp_vocabs)\n",
    "            test_results = evaluate_fixed(model, slurp_test_loader, \"slot\")\n",
    "            results['SLURP_Slot_Independent'] = test_results\n",
    "            print(f\" Slot Model: {test_results.get('slot_accuracy', 0):.4f} accuracy\")\n",
    "        except Exception as e:\n",
    "            print(f\" SLURP Slot Model: Error - {e}\")\n",
    "    \n",
    "    if os.path.exists(\"saved_models/slurp_joint_model.pth\"):\n",
    "        try:\n",
    "            model = load_slurp_joint_model(\"saved_models/slurp_joint_model.pth\", slurp_vocabs)\n",
    "            test_results = evaluate_fixed(model, slurp_test_loader, \"joint\")\n",
    "            results['SLURP_Joint'] = test_results\n",
    "            print(f\" Joint Model: Intent={test_results.get('intent_accuracy', 0):.4f}, Slot={test_results.get('slot_accuracy', 0):.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\" SLURP Joint Model: Error - {e}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\" PERFORMANCE COMPARISON SUMMARY\")\n",
    "    \n",
    "    print(f\"{'Model':<30} | {'Intent Acc':<10} | {'Intent F1':<10} | {'Slot Acc':<10} | {'Slot F1':<10}\")\n",
    "    \n",
    "    \n",
    "    for model_name, metrics in results.items():\n",
    "        intent_acc = f\"{metrics.get('intent_accuracy', 0):.4f}\" if 'intent_accuracy' in metrics else \"N/A\"\n",
    "        intent_f1 = f\"{metrics.get('intent_f1_macro', 0):.4f}\" if 'intent_f1_macro' in metrics else \"N/A\"\n",
    "        slot_acc = f\"{metrics.get('slot_accuracy', 0):.4f}\" if 'slot_accuracy' in metrics else \"N/A\"\n",
    "        slot_f1 = f\"{metrics.get('slot_f1_macro', 0):.4f}\" if 'slot_f1_macro' in metrics else \"N/A\"\n",
    "        \n",
    "        print(f\"{model_name:<30} | {intent_acc:<10} | {intent_f1:<10} | {slot_acc:<10} | {slot_f1:<10}\")\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    \n",
    "    print(\"\\n KEY INSIGHTS:\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    atis_intent_models = {k: v for k, v in results.items() if 'ATIS' in k and 'intent_accuracy' in v}\n",
    "    atis_slot_models = {k: v for k, v in results.items() if 'ATIS' in k and 'slot_accuracy' in v}\n",
    "    slurp_intent_models = {k: v for k, v in results.items() if 'SLURP' in k and 'intent_accuracy' in v}\n",
    "    slurp_slot_models = {k: v for k, v in results.items() if 'SLURP' in k and 'slot_accuracy' in v}\n",
    "    \n",
    "    if atis_intent_models:\n",
    "        best_atis_intent = max(atis_intent_models.items(), key=lambda x: x[1]['intent_accuracy'])\n",
    "        print(f\" Best ATIS Intent Model: {best_atis_intent[0]} ({best_atis_intent[1]['intent_accuracy']:.4f})\")\n",
    "    \n",
    "    if atis_slot_models:\n",
    "        best_atis_slot = max(atis_slot_models.items(), key=lambda x: x[1]['slot_accuracy'])\n",
    "        print(f\" Best ATIS Slot Model: {best_atis_slot[0]} ({best_atis_slot[1]['slot_accuracy']:.4f})\")\n",
    "    \n",
    "    if slurp_intent_models:\n",
    "        best_slurp_intent = max(slurp_intent_models.items(), key=lambda x: x[1]['intent_accuracy'])\n",
    "        print(f\" Best SLURP Intent Model: {best_slurp_intent[0]} ({best_slurp_intent[1]['intent_accuracy']:.4f})\")\n",
    "    \n",
    "    if slurp_slot_models:\n",
    "        best_slurp_slot = max(slurp_slot_models.items(), key=lambda x: x[1]['slot_accuracy'])\n",
    "        print(f\" Best SLURP Slot Model: {best_slurp_slot[0]} ({best_slurp_slot[1]['slot_accuracy']:.4f})\")\n",
    "\n",
    "\n",
    "def show_model_performance():\n",
    "    \"\"\"Show performance without running evaluation (uses your experiment results)\"\"\"\n",
    "    print(\" MODEL PERFORMANCE SUMMARY\")\n",
    "    \n",
    "    print(\"\\n ATIS DATASET (Flight Booking)\")\n",
    "    \n",
    "    print(f\"{'Model':<25} | {'Intent Acc':<10} | {'Slot Acc':<10} | {'Description'}\")\n",
    "    \n",
    "    print(f\"{'Intent Model':<25} | {'0.9518':<10} | {'N/A':<10} | {'Only predicts flight intent'}\")\n",
    "    print(f\"{'Slot Model':<25} | {'N/A':<10} | {'0.9987':<10} | {'Only predicts flight entities'}\")\n",
    "    print(f\"{'Joint Model':<25} | {'0.9485':<10} | {'0.9992':<10} | {'Predicts both simultaneously'}\")\n",
    "    \n",
    "    print(\"\\n SLURP DATASET (General Commands)\")\n",
    "    \n",
    "    print(f\"{'Model':<25} | {'Intent Acc':<10} | {'Slot Acc':<10} | {'Description'}\")\n",
    "    \n",
    "    print(f\"{'Intent Model':<25} | {'0.7872':<10} | {'N/A':<10} | {'Only predicts command type'}\")\n",
    "    print(f\"{'Slot Model':<25} | {'N/A':<10} | {'0.6699':<10} | {'Only predicts entities'}\")\n",
    "    print(f\"{'Joint Model':<25} | {'0.7784':<10} | {'0.6369':<10} | {'Predicts both simultaneously'}\")\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "def quick_model_test():\n",
    "    \n",
    "    print(\" QUICK MODEL TEST\")\n",
    "   \n",
    "    \n",
    "    examples = {\n",
    "        \"ATIS\": [\n",
    "            \"show me flights from boston to san francisco\",\n",
    "            \"what is the cheapest fare to los angeles\"\n",
    "        ],\n",
    "        \"SLURP\": [\n",
    "            \"play some jazz music\",\n",
    "            \"set alarm for 7 am tomorrow\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for dataset, sentences in examples.items():\n",
    "        print(f\"\\n {dataset} Examples:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            print(f\"\\n '{sentence}'\")\n",
    "            \n",
    "            if dataset == \"ATIS\" and os.path.exists(\"saved_models/joint_model.pth\"):\n",
    "                try:\n",
    "                    model = load_model_for_inference(\"saved_models/joint_model.pth\", \"joint\", atis_vocabs)\n",
    "                    intent, slots = predict_joint(sentence, model, atis_vocabs)\n",
    "                    print(f\"  Intent: {intent}\")\n",
    "                    print(f\"  Slots: {[f'{token}‚Üí{slot}' for token, slot in slots if slot != 'O']}\")\n",
    "                except:\n",
    "                    print(\"  Model not available\")\n",
    "            \n",
    "            elif dataset == \"SLURP\" and os.path.exists(\"saved_models/slurp_joint_model.pth\"):\n",
    "                try:\n",
    "                    model = load_slurp_joint_model(\"saved_models/slurp_joint_model.pth\", slurp_vocabs)\n",
    "                    intent, slots = predict_joint(sentence, model, slurp_vocabs)\n",
    "                    print(f\"  Intent: {intent}\")\n",
    "                    print(f\"  Slots: {[f'{token}‚Üí{slot}' for token, slot in slots if slot != 'O']}\")\n",
    "                except:\n",
    "                    print(\"   Model not available\")\n",
    "\n",
    "\n",
    "print(\"Ready to compare models! Run one of these:\")\n",
    "print(\"1. compare_all_models() - Full evaluation (needs test data)\")\n",
    "print(\"2. show_model_performance() - Quick summary\")\n",
    "print(\"3. quick_model_test() - Test with examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e0aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MODEL PERFORMANCE SUMMARY\n",
      "\n",
      " ATIS DATASET (Flight Booking)\n",
      "Model                     | Intent Acc | Slot Acc   | Description\n",
      "Intent Model              | 0.9518     | N/A        | Only predicts flight intent\n",
      "Slot Model                | N/A        | 0.9987     | Only predicts flight entities\n",
      "Joint Model               | 0.9485     | 0.9992     | Predicts both simultaneously\n",
      "\n",
      " SLURP DATASET (General Commands)\n",
      "Model                     | Intent Acc | Slot Acc   | Description\n",
      "Intent Model              | 0.7872     | N/A        | Only predicts command type\n",
      "Slot Model                | N/A        | 0.6699     | Only predicts entities\n",
      "Joint Model               | 0.7784     | 0.6369     | Predicts both simultaneously\n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_model_performance()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
