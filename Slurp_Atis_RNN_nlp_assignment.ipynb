{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "febde872aad84a5da8a52910e5bb9dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d21be6494284b0f93ea92cc92a342cc",
              "IPY_MODEL_33d2d5d729fc446caebeae0b69043764",
              "IPY_MODEL_362c8dae55974548b554fc45affdd268"
            ],
            "layout": "IPY_MODEL_4325ba8513974de983f237f81b0ab0f6"
          }
        },
        "2d21be6494284b0f93ea92cc92a342cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21c8f4cdbe54ce0be0ac3b8ed16e9d1",
            "placeholder": "​",
            "style": "IPY_MODEL_cc38ff1c8ecd40cea00207a2b0375e10",
            "value": "atis_train.csv: "
          }
        },
        "33d2d5d729fc446caebeae0b69043764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7140a7f26154163bf2217aea533ca6f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07fcf63ecede426f8dadf76fad9ead8c",
            "value": 1
          }
        },
        "362c8dae55974548b554fc45affdd268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21967696c57b4225985d308158c04046",
            "placeholder": "​",
            "style": "IPY_MODEL_7c94885709a9436bb6b63f60b090f1b4",
            "value": " 850k/? [00:00&lt;00:00, 52.2MB/s]"
          }
        },
        "4325ba8513974de983f237f81b0ab0f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21c8f4cdbe54ce0be0ac3b8ed16e9d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc38ff1c8ecd40cea00207a2b0375e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7140a7f26154163bf2217aea533ca6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "07fcf63ecede426f8dadf76fad9ead8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21967696c57b4225985d308158c04046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c94885709a9436bb6b63f60b090f1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94627ebddde247e5a1e0f43078494d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c263e9d1b594f35932f31ac5b21c389",
              "IPY_MODEL_2a3dc44f56b54e0f8936a1503c4fa912",
              "IPY_MODEL_cd9fd30f100d40fdad9b378b2f710644"
            ],
            "layout": "IPY_MODEL_0a60008377744cafbbbfdad51eac2e63"
          }
        },
        "6c263e9d1b594f35932f31ac5b21c389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b21081b66ba44e70bafcff4c7b9ec7c6",
            "placeholder": "​",
            "style": "IPY_MODEL_071730f2413b4c968718e2f02321b98d",
            "value": "atis_test.csv: "
          }
        },
        "2a3dc44f56b54e0f8936a1503c4fa912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a73bb722f9a46cd96bca85ffb94bbf6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f855b07c9f6482e9f70e1fb03315bee",
            "value": 1
          }
        },
        "cd9fd30f100d40fdad9b378b2f710644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_568d14717f7f424c943b418c7098a332",
            "placeholder": "​",
            "style": "IPY_MODEL_81aa807ff7554a9588b80a0123172b28",
            "value": " 144k/? [00:00&lt;00:00, 14.3MB/s]"
          }
        },
        "0a60008377744cafbbbfdad51eac2e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21081b66ba44e70bafcff4c7b9ec7c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071730f2413b4c968718e2f02321b98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a73bb722f9a46cd96bca85ffb94bbf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7f855b07c9f6482e9f70e1fb03315bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "568d14717f7f424c943b418c7098a332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81aa807ff7554a9588b80a0123172b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "136b4d9bb1ba40c0b0c08f4a86108357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca56695ddafa4c6ab3f92c9b00bb4296",
              "IPY_MODEL_473f9fef4f404e59b954f770521613b8",
              "IPY_MODEL_75d6392ac940402da01efbfebad9ac42"
            ],
            "layout": "IPY_MODEL_6f1dfe00db584e2f9304344287237004"
          }
        },
        "ca56695ddafa4c6ab3f92c9b00bb4296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de657a6ef3a24e20891e678b1ed5c9a5",
            "placeholder": "​",
            "style": "IPY_MODEL_c2d84f3adadb4a41a285a27ceeeed602",
            "value": "Generating train split: 100%"
          }
        },
        "473f9fef4f404e59b954f770521613b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_372b21701f1f4df39515cbb9ee6ca6f8",
            "max": 4978,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04e3596029404ff3b179004cea5b4de9",
            "value": 4978
          }
        },
        "75d6392ac940402da01efbfebad9ac42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aaa598dec4f44f0aca38aba57e20a40",
            "placeholder": "​",
            "style": "IPY_MODEL_6f5ceefcb64c44bb85392a02da1e5593",
            "value": " 4978/4978 [00:00&lt;00:00, 71883.87 examples/s]"
          }
        },
        "6f1dfe00db584e2f9304344287237004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de657a6ef3a24e20891e678b1ed5c9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d84f3adadb4a41a285a27ceeeed602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "372b21701f1f4df39515cbb9ee6ca6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e3596029404ff3b179004cea5b4de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6aaa598dec4f44f0aca38aba57e20a40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5ceefcb64c44bb85392a02da1e5593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fbbcd9bf0fd40afbbee610d15869c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a45d6e6c363148f18c189772167f82a8",
              "IPY_MODEL_ffef27528adc48b3b83bfd3417bc8eed",
              "IPY_MODEL_83b4adc80dd2488c995e67f03dddecd4"
            ],
            "layout": "IPY_MODEL_beb0f6e5c395415da2b58e5b6b1d5756"
          }
        },
        "a45d6e6c363148f18c189772167f82a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c871a9574c0549a2a88245b15138e9fa",
            "placeholder": "​",
            "style": "IPY_MODEL_6152e84e4b074c2cae298182fd11caac",
            "value": "Generating test split: 100%"
          }
        },
        "ffef27528adc48b3b83bfd3417bc8eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1386077a2d324cb296ee04ae4dbeec0e",
            "max": 893,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb4bb6c23bd7463191056a0ae3190a65",
            "value": 893
          }
        },
        "83b4adc80dd2488c995e67f03dddecd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de8580dae6c44a6ab3e890429b9a7cd",
            "placeholder": "​",
            "style": "IPY_MODEL_b24cb884a2a24c13acdfc92522a20de5",
            "value": " 893/893 [00:00&lt;00:00, 29634.34 examples/s]"
          }
        },
        "beb0f6e5c395415da2b58e5b6b1d5756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c871a9574c0549a2a88245b15138e9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6152e84e4b074c2cae298182fd11caac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1386077a2d324cb296ee04ae4dbeec0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb4bb6c23bd7463191056a0ae3190a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9de8580dae6c44a6ab3e890429b9a7cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24cb884a2a24c13acdfc92522a20de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ATIS DATASET"
      ],
      "metadata": {
        "id": "DcpIewhEn9Yj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTtIGNwUnslp",
        "outputId": "9fa9e350-4f8b-485b-e665-926d13c2fcd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load train data and test data"
      ],
      "metadata": {
        "id": "-OZtkfuNoFV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "atis_dataset = load_dataset(\"tuetschek/atis\")\n",
        "print(atis_dataset)\n",
        "train_data=atis_dataset[\"train\"]\n",
        "print(train_data)\n",
        "no_of_samples=len(train_data)\n",
        "print(no_of_samples)\n",
        "test_data=atis_dataset[\"test\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530,
          "referenced_widgets": [
            "febde872aad84a5da8a52910e5bb9dde",
            "2d21be6494284b0f93ea92cc92a342cc",
            "33d2d5d729fc446caebeae0b69043764",
            "362c8dae55974548b554fc45affdd268",
            "4325ba8513974de983f237f81b0ab0f6",
            "b21c8f4cdbe54ce0be0ac3b8ed16e9d1",
            "cc38ff1c8ecd40cea00207a2b0375e10",
            "a7140a7f26154163bf2217aea533ca6f",
            "07fcf63ecede426f8dadf76fad9ead8c",
            "21967696c57b4225985d308158c04046",
            "7c94885709a9436bb6b63f60b090f1b4",
            "94627ebddde247e5a1e0f43078494d89",
            "6c263e9d1b594f35932f31ac5b21c389",
            "2a3dc44f56b54e0f8936a1503c4fa912",
            "cd9fd30f100d40fdad9b378b2f710644",
            "0a60008377744cafbbbfdad51eac2e63",
            "b21081b66ba44e70bafcff4c7b9ec7c6",
            "071730f2413b4c968718e2f02321b98d",
            "5a73bb722f9a46cd96bca85ffb94bbf6",
            "7f855b07c9f6482e9f70e1fb03315bee",
            "568d14717f7f424c943b418c7098a332",
            "81aa807ff7554a9588b80a0123172b28",
            "136b4d9bb1ba40c0b0c08f4a86108357",
            "ca56695ddafa4c6ab3f92c9b00bb4296",
            "473f9fef4f404e59b954f770521613b8",
            "75d6392ac940402da01efbfebad9ac42",
            "6f1dfe00db584e2f9304344287237004",
            "de657a6ef3a24e20891e678b1ed5c9a5",
            "c2d84f3adadb4a41a285a27ceeeed602",
            "372b21701f1f4df39515cbb9ee6ca6f8",
            "04e3596029404ff3b179004cea5b4de9",
            "6aaa598dec4f44f0aca38aba57e20a40",
            "6f5ceefcb64c44bb85392a02da1e5593",
            "3fbbcd9bf0fd40afbbee610d15869c90",
            "a45d6e6c363148f18c189772167f82a8",
            "ffef27528adc48b3b83bfd3417bc8eed",
            "83b4adc80dd2488c995e67f03dddecd4",
            "beb0f6e5c395415da2b58e5b6b1d5756",
            "c871a9574c0549a2a88245b15138e9fa",
            "6152e84e4b074c2cae298182fd11caac",
            "1386077a2d324cb296ee04ae4dbeec0e",
            "cb4bb6c23bd7463191056a0ae3190a65",
            "9de8580dae6c44a6ab3e890429b9a7cd",
            "b24cb884a2a24c13acdfc92522a20de5"
          ]
        },
        "id": "Ct70PwQ0oJeF",
        "outputId": "5256a609-57cf-428f-a70c-e2ba7bdb8dd9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "atis_train.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "febde872aad84a5da8a52910e5bb9dde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "atis_test.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94627ebddde247e5a1e0f43078494d89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4978 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "136b4d9bb1ba40c0b0c08f4a86108357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/893 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fbbcd9bf0fd40afbbee610d15869c90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'intent', 'text', 'slots'],\n",
            "        num_rows: 4978\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'intent', 'text', 'slots'],\n",
            "        num_rows: 893\n",
            "    })\n",
            "})\n",
            "Dataset({\n",
            "    features: ['id', 'intent', 'text', 'slots'],\n",
            "    num_rows: 4978\n",
            "})\n",
            "4978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a vocabulary for text"
      ],
      "metadata": {
        "id": "evscLhYloMM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_vocabulary=set()\n",
        "for sentence in train_data['text']:\n",
        "  unique_vocabulary.update(sentence.split())\n",
        "word_vocab={\"<pad>\":0, \"<unk>\":1}\n",
        "for word in unique_vocabulary:\n",
        "  word_vocab[word]=len(word_vocab)\n",
        "print(word_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn_guGOqoLqI",
        "outputId": "a41251b7-e1a7-4e30-ef75-d3480e5a4760"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, '<unk>': 1, '7': 2, 'originate': 3, 'm': 4, 's': 5, '416': 6, 'companies': 7, 'some': 8, 'seventeenth': 9, '1000': 10, 'o': 11, '718': 12, 'ewr': 13, 'j31': 14, 'so': 15, '402': 16, 'q': 17, 'arrangements': 18, 'limousines': 19, 'repeat': 20, 'offers': 21, 'stands': 22, 'jfk': 23, 'georgia': 24, 'lastest': 25, 'expensive': 26, '420': 27, '1992': 28, 'or': 29, 'california': 30, 'names': 31, 'ninth': 32, 'options': 33, '838': 34, 'after': 35, '2': 36, 'eleventh': 37, 'thirty': 38, 'f28': 39, 'dfw': 40, 'following': 41, '1300': 42, '4': 43, 'francisco': 44, '1110': 45, 'michigan': 46, 'non': 47, 'now': 48, 'me': 49, 'off': 50, 'then': 51, 'transport': 52, 'used': 53, 'capacity': 54, 'landing': 55, 'arriving': 56, 'ff': 57, 'number': 58, 'texas': 59, 'sixteen': 60, '1130': 61, 'fit': 62, '257': 63, 'sorry': 64, 'world': 65, 'airport': 66, 'united': 67, '271': 68, 'detroit': 69, 'takes': 70, '539': 71, 'closest': 72, 'aa': 73, 'snack': 74, 'only': 75, '11': 76, '1220': 77, 'before': 78, '845': 79, 'able': 80, 'makes': 81, 'route': 82, 'seattle': 83, 'class': 84, 'salt': 85, 'nonstop': 86, 'weekday': 87, '823': 88, 'bound': 89, 'out': 90, 'take': 91, 'continental': 92, 'stapleton': 93, 'please': 94, 'without': 95, '1020': 96, 'up': 97, 'people': 98, 'under': 99, 'at': 100, '771': 101, 'rentals': 102, 'quebec': 103, 'anything': 104, 'washington': 105, '1222': 106, '137338': 107, 'fare': 108, 'much': 109, 'supper': 110, '201': 111, 'level': 112, 'saturday': 113, '1059': 114, 'abbreviations': 115, 'smallest': 116, '1600': 117, 'over': 118, 'stopping': 119, '727': 120, 'their': 121, 'includes': 122, 'into': 123, 'than': 124, 'across': 125, 'economic': 126, 'them': 127, 'august': 128, 'various': 129, 'soon': 130, 'general': 131, 'doesn': 132, 'connects': 133, 'thank': 134, 'flights': 135, 'ticket': 136, 'saturdays': 137, 'classes': 138, 'proper': 139, 'eighteenth': 140, 'preferably': 141, 'know': 142, 'as': 143, 'late': 144, 'weekdays': 145, '1205': 146, 'month': 147, 'arizona': 148, '300': 149, 'don': 150, '819': 151, 'listed': 152, 'has': 153, '130': 154, 'fine': 155, 'of': 156, 'like': 157, 'mco': 158, 'am': 159, 'december': 160, 'guardia': 161, 'nights': 162, '767': 163, '210': 164, 'days': 165, 'traveling': 166, 'next': 167, 'say': 168, 'need': 169, 'twentieth': 170, 'friends': 171, 'utah': 172, 'san': 173, 'northwest': 174, 'october': 175, '296': 176, 'again': 177, 'between': 178, 'services': 179, 'straight': 180, 'week': 181, 'tomorrow': 182, '106': 183, 'january': 184, 'via': 185, 'year': 186, 'cities': 187, 'atl': 188, 'night': 189, 'reverse': 190, 'lowest': 191, 'i': 192, 'newark': 193, 'day': 194, 'pennsylvania': 195, 'time': 196, '124': 197, 'being': 198, 'home': 199, 'airports': 200, 'nashville': 201, 'one': 202, 'using': 203, 'find': 204, 'service': 205, '10': 206, 'spend': 207, \"'t\": 208, 'belong': 209, 'fifteenth': 210, 'seating': 211, 'served': 212, 'reaches': 213, 'dallas': 214, 'monday': 215, 'eight': 216, \"o'clock\": 217, 'look': 218, '555': 219, 'afternoons': 220, 'restriction': 221, 'dinnertime': 222, 'today': 223, 'sometime': 224, 'intercontinental': 225, 'b': 226, '352': 227, 'm80': 228, '1940': 229, 'la': 230, 'airfare': 231, 'long': 232, \"'d\": 233, 'd10': 234, 'chicago': 235, 'colorado': 236, 'bring': 237, 'got': 238, 'an': 239, 'dl': 240, 'worth': 241, 'love': 242, '1200': 243, 'limousine': 244, 'starting': 245, 'want': 246, 'philadelphia': 247, 'takeoff': 248, 'possible': 249, 'milwaukee': 250, 'capacities': 251, '6': 252, 'offer': 253, 'airline': 254, 'have': 255, 'hi': 256, 'your': 257, 'rates': 258, '1288': 259, 'reaching': 260, 'twenty': 261, 'march': 262, 'fares': 263, 'tower': 264, '730': 265, 'carolina': 266, 'earliest': 267, 'thanks': 268, '1291': 269, 'well': 270, 'hello': 271, 'should': 272, 'usa': 273, 'largest': 274, 'sunday': 275, 'alaska': 276, 'economy': 277, 'to': 278, 'regarding': 279, 'live': 280, 'sixteenth': 281, 'return': 282, 'these': 283, '329': 284, 'do': 285, 'having': 286, 'meaning': 287, 'vegas': 288, 'planes': 289, 'determine': 290, 'still': 291, 'layover': 292, 'ls': 293, 'around': 294, 'mealtime': 295, '1245': 296, 'serve': 297, 'h': 298, '55': 299, 'maximum': 300, '645': 301, 'orlando': 302, 'inform': 303, 'put': 304, 'working': 305, 'kindly': 306, 'memphis': 307, 'we': 308, 'let': 309, 'scheduled': 310, 'by': 311, 'oh': 312, 'provides': 313, 'calling': 314, 'yyz': 315, 'thursday': 316, 'thereafter': 317, 'could': 318, 'fourteenth': 319, 'miami': 320, 'july': 321, '815': 322, 'start': 323, 'enroute': 324, 'show': 325, 'fifth': 326, 'jersey': 327, 'third': 328, 'also': 329, 'does': 330, 'twa': 331, 'they': 332, 'lives': 333, 'choices': 334, 'run': 335, 'noon': 336, 'four': 337, 'many': 338, '1145': 339, 'june': 340, '345': 341, 'serving': 342, '400': 343, 'car': 344, 'transportation': 345, '12': 346, 'if': 347, 'final': 348, 'place': 349, 'cover': 350, 'nationair': 351, 'come': 352, 'taking': 353, 'houston': 354, '428': 355, 'tickets': 356, 'heading': 357, 'most': 358, 'aircraft': 359, 'right': 360, 'delta': 361, 'departure': 362, '1039': 363, 'make': 364, 'explain': 365, 'yes': 366, 'including': 367, 'september': 368, 'cars': 369, 'during': 370, 'define': 371, 'laying': 372, 'cincinnati': 373, 'thing': 374, 'oak': 375, 'eastern': 376, 'local': 377, 'this': 378, 'indiana': 379, '4400': 380, 'minnesota': 381, 'dc10': 382, 'listings': 383, '928': 384, 'qx': 385, 'southwest': 386, 'burbank': 387, 'must': 388, '80': 389, 'bay': 390, '217': 391, 'lester': 392, '1055': 393, 'evening': 394, '110': 395, '163': 396, 'go': 397, 'hou': 398, 'f': 399, 'connection': 400, 'there': 401, 'seventeen': 402, 'trying': 403, 'november': 404, 'plan': 405, 'continent': 406, 'ap': 407, '5': 408, 'afterwards': 409, 'will': 410, 'on': 411, 'least': 412, 'thirteenth': 413, 'it': 414, 'denver': 415, 'looking': 416, 'who': 417, 'ontario': 418, 'ac': 419, 'besides': 420, 'ap57': 421, 'abbreviation': 422, '430': 423, 'going': 424, 'display': 425, 'phoenix': 426, '343': 427, 'atlanta': 428, 'ten': 429, 'daily': 430, 'can': 431, '324': 432, 'bwi': 433, 'continuing': 434, 'and': 435, 'sure': 436, 'schedule': 437, 'morning': 438, 'dulles': 439, 'listing': 440, '757': 441, 'offered': 442, 'ua': 443, 'passengers': 444, 'less': 445, 'database': 446, '1026': 447, '98': 448, 'while': 449, 'itinerary': 450, 'afternoon': 451, '934': 452, 'boeing': 453, 'ea': 454, 'bur': 455, 'twelfth': 456, '1700': 457, '269': 458, 'missouri': 459, 'breakfast': 460, 'such': 461, 'ord': 462, '3': 463, 'connections': 464, \"'hare\": 465, 'carried': 466, 'costs': 467, 'reservations': 468, '505': 469, 'twelve': 470, 'hours': 471, 'air': 472, 'field': 473, 'advertises': 474, 'leaving': 475, 'airfares': 476, '3357': 477, '405': 478, 'runs': 479, '737': 480, 'fn': 481, 'through': 482, 'york': 483, 'oakland': 484, 'zone': 485, 'be': 486, 'far': 487, 'too': 488, '1017': 489, 'see': 490, 'diego': 491, 'toward': 492, 'midwest': 493, 'discount': 494, 'leave': 495, 'county': 496, '445': 497, 'catch': 498, 'else': 499, '229': 500, 'yn': 501, 'lunch': 502, 'equipment': 503, 'canadian': 504, 'international': 505, '1115': 506, 'hartfield': 507, 'meals': 508, 'tuesdays': 509, 'prices': 510, 'may': 511, 'gets': 512, 'y': 513, 'any': 514, 'mitchell': 515, 'lufthansa': 516, 'sd': 517, 'lake': 518, 'second': 519, '1765': 520, 'mia': 521, '9': 522, 'those': 523, 'numbers': 524, 'both': 525, '139': 526, 'single': 527, 'book': 528, 'times': 529, 'taxi': 530, 'charges': 531, 'a': 532, 'february': 533, '1991': 534, 'requesting': 535, '515': 536, 'direct': 537, '630': 538, 'co': 539, 'question': 540, '650': 541, 'originating': 542, 'greatest': 543, 'available': 544, 'arrives': 545, 'stopovers': 546, 'flight': 547, 'currently': 548, 'tampa': 549, '150': 550, 'another': 551, 'concerning': 552, 'north': 553, 'indianapolis': 554, 'types': 555, 'nw': 556, 'cleveland': 557, 'charlotte': 558, '500': 559, 'once': 560, 'midnight': 561, '57': 562, '723': 563, 'restrictions': 564, 'help': 565, '311': 566, 'los': 567, 'kansas': 568, 'list': 569, 'land': 570, 'wednesday': 571, '0900': 572, 'first': 573, 'express': 574, '230': 575, '8': 576, '1209': 577, 'beach': 578, 'total': 579, 'code': 580, 'st.': 581, 'equal': 582, 'fifteen': 583, 'tacoma': 584, '305': 585, 'mean': 586, 'toronto': 587, 'nonstops': 588, 'along': 589, 'eighth': 590, '417': 591, 'qo': 592, 'approximately': 593, 'ground': 594, 'stop': 595, 'sa': 596, '746': 597, '734': 598, 'flies': 599, 'scenario': 600, \"'s\": 601, 'trip': 602, 'begins': 603, 'departing': 604, 'the': 605, 'instead': 606, 'try': 607, 'hopefully': 608, 'information': 609, 'represented': 610, 'travels': 611, 'schedules': 612, 'later': 613, 'limo': 614, 'overnight': 615, 'but': 616, 'philly': 617, '212': 618, 'buy': 619, '1133': 620, '733': 621, 'distance': 622, 'dollars': 623, '71': 624, 'transcontinental': 625, 'pearson': 626, 'town': 627, 'for': 628, 'paul': 629, 'nevada': 630, 'great': 631, 'reservation': 632, 'lax': 633, 'just': 634, 'wanted': 635, 'amount': 636, '2153': 637, 'landings': 638, 'very': 639, 'operation': 640, 'destination': 641, '270': 642, '1505': 643, 'longest': 644, '200': 645, 'april': 646, 'priced': 647, '1030': 648, 'dinner': 649, '1158': 650, '1': 651, 'pm': 652, 'fort': 653, 'prefer': 654, '281': 655, 'everywhere': 656, 'hold': 657, 'are': 658, '466': 659, \"'ve\": 660, 'get': 661, 'airplane': 662, '323': 663, 'rental': 664, 'sounds': 665, 'different': 666, 'montreal': 667, 'turboprop': 668, 'angeles': 669, '2100': 670, 'arrive': 671, '415': 672, 'sort': 673, 'plane': 674, '459': 675, 'with': 676, 'okay': 677, 'minneapolis': 678, 'beginning': 679, 'give': 680, 'locate': 681, 'red': 682, 'operating': 683, 'trans': 684, 'flying': 685, 'thursdays': 686, 'codes': 687, 'thirtieth': 688, 'summer': 689, 'meal': 690, 'logan': 691, 'is': 692, 'either': 693, 'depart': 694, '1024': 695, 'way': 696, '755': 697, '852': 698, 'how': 699, 'boston': 700, '100': 701, 'which': 702, 'sundays': 703, '1083': 704, 'anywhere': 705, 'dc': 706, 'cheapest': 707, 'connecting': 708, '810': 709, 'us': 710, 'actually': 711, 'seven': 712, '720': 713, 'mornings': 714, 'stopover': 715, '82': 716, 'tennessee': 717, 'minimum': 718, 'within': 719, 'you': 720, 'would': 721, 'booking': 722, 'bna': 723, '530': 724, '747': 725, 'here': 726, 'from': 727, 'travel': 728, \"'ll\": 729, 'planning': 730, 'nineteenth': 731, '1850': 732, '279': 733, 'uses': 734, 'westchester': 735, 'business': 736, 'round': 737, 'stops': 738, 'near': 739, 'provide': 740, 'ap68': 741, 'my': 742, '1500': 743, 'nighttime': 744, 'petersburg': 745, 'shortest': 746, 'visit': 747, 'new': 748, 'train': 749, 'downtown': 750, 'each': 751, 'repeating': 752, 'pittsburgh': 753, 'jet': 754, 'wish': 755, '3724': 756, 'cheap': 757, 'seat': 758, 'wants': 759, 'airlines': 760, 'louis': 761, 'what': 762, 'stand': 763, 'provided': 764, 'making': 765, 'in': 766, 'directly': 767, 'eye': 768, 'connect': 769, 'tuesday': 770, 'more': 771, 'd': 772, 'trips': 773, 'serviced': 774, 'arrange': 775, 'seats': 776, '19': 777, 'arrivals': 778, 'where': 779, 'cost': 780, 'use': 781, 'grounds': 782, 'describe': 783, 'city': 784, 'designate': 785, 'departs': 786, 'located': 787, 'baltimore': 788, 'whether': 789, 'latest': 790, 'canada': 791, 'mondays': 792, 'back': 793, 'symbols': 794, 'vicinity': 795, 'fly': 796, 'price': 797, 'las': 798, 'area': 799, '225': 800, 'tenth': 801, 'arrival': 802, 'leaves': 803, 'wednesdays': 804, '825': 805, 'goes': 806, 'fourth': 807, 'three': 808, 'close': 809, '21': 810, 'airplanes': 811, 'interested': 812, 'eleven': 813, 'inexpensive': 814, 'qualify': 815, 'date': 816, '43': 817, 'seventh': 818, 'thrift': 819, 'rent': 820, 'two': 821, 'west': 822, 'same': 823, 'highest': 824, '1993': 825, 'about': 826, '315': 827, '615': 828, 'hp': 829, 'order': 830, 'name': 831, 'american': 832, 'tonight': 833, 'ap80': 834, 'serves': 835, '72s': 836, 'returning': 837, 'midway': 838, '1045': 839, 'ohio': 840, 'difference': 841, 'early': 842, '1100': 843, '2134': 844, \"'m\": 845, 'jose': 846, '813': 847, 'no': 848, 'all': 849, '932': 850, 'kinds': 851, 'd9s': 852, 'other': 853, 'cp': 854, '1230': 855, 'kind': 856, 'noontime': 857, 'type': 858, 'six': 859, 'that': 860, 'florida': 861, 'sixth': 862, 'k': 863, 'coming': 864, \"'re\": 865, '73s': 866, '297': 867, 'iah': 868, 'last': 869, 'america': 870, 'sfo': 871, 'when': 872, '497766': 873, 'include': 874, 'staying': 875, 'lands': 876, 'takeoffs': 877, 'rate': 878, 'fridays': 879, 'tell': 880, 'coach': 881, 'somebody': 882, 'columbus': 883, 'departures': 884, 'friday': 885, 'carries': 886, 'earlier': 887, 'qw': 888, 'c': 889, '705': 890}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a vocabulary for intent"
      ],
      "metadata": {
        "id": "rDjLgRPaoXs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_list=list(set(train_data['intent']))\n",
        "intent_vocab = {'<unk>': 0}\n",
        "for intent in intent_list:\n",
        "  intent_vocab[intent] = len(intent_vocab)\n",
        "print(intent_vocab)\n",
        "print(len(intent_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG_GvWOXoaz7",
        "outputId": "13c2b8c5-5d6f-402b-8ea9-24f1d0efed27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<unk>': 0, 'airline+flight_no': 1, 'ground_service': 2, 'flight_time': 3, 'distance': 4, 'abbreviation': 5, 'restriction': 6, 'airport': 7, 'quantity': 8, 'meal': 9, 'flight_no': 10, 'airfare': 11, 'flight+airfare': 12, 'cheapest': 13, 'ground_service+ground_fare': 14, 'aircraft': 15, 'airline': 16, 'aircraft+flight+flight_no': 17, 'airfare+flight_time': 18, 'ground_fare': 19, 'city': 20, 'flight': 21, 'capacity': 22}\n",
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a vocabulary for slot"
      ],
      "metadata": {
        "id": "ZV0SCly3od8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slots_data=train_data['slots']\n",
        "slots_labels=[slots.split() for slots in slots_data]\n",
        "slot_unique_labels=set()\n",
        "for slots in slots_labels:\n",
        "  slot_unique_labels.update(slots)\n",
        "slot_unique_labels=list(slot_unique_labels)\n",
        "slot_vocab={slot_label:i+2 for i,slot_label in enumerate(slot_unique_labels)}\n",
        "slot_vocab['<unk>']=1\n",
        "slot_vocab['<pad>']=0\n",
        "print(slot_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz5EXN1KoiWW",
        "outputId": "4e53285f-07f5-48bd-da72-a295e7c8e24f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-state_name': 2, 'B-class_type': 3, 'B-depart_date.today_relative': 4, 'B-depart_date.day_name': 5, 'B-toloc.airport_code': 6, 'I-airport_name': 7, 'B-return_date.today_relative': 8, 'B-meal_code': 9, 'I-arrive_time.time_relative': 10, 'B-return_date.day_number': 11, 'I-meal_code': 12, 'B-fare_basis_code': 13, 'B-day_name': 14, 'B-arrive_date.today_relative': 15, 'B-toloc.state_code': 16, 'I-arrive_time.time': 17, 'B-depart_time.end_time': 18, 'B-stoploc.city_name': 19, 'B-cost_relative': 20, 'B-depart_time.start_time': 21, 'B-round_trip': 22, 'I-cost_relative': 23, 'B-arrive_date.month_name': 24, 'B-arrive_time.end_time': 25, 'B-return_time.period_mod': 26, 'B-depart_time.time_relative': 27, 'I-round_trip': 28, 'B-fromloc.airport_name': 29, 'B-depart_time.period_of_day': 30, 'I-depart_time.time': 31, 'I-airline_name': 32, 'I-return_date.today_relative': 33, 'B-return_date.day_name': 34, 'I-depart_date.today_relative': 35, 'B-transport_type': 36, 'B-or': 37, 'B-depart_date.month_name': 38, 'I-fromloc.airport_name': 39, 'I-fare_amount': 40, 'B-state_code': 41, 'I-today_relative': 42, 'B-fromloc.city_name': 43, 'B-arrive_date.day_number': 44, 'B-time': 45, 'I-return_date.day_number': 46, 'I-mod': 47, 'B-toloc.city_name': 48, 'B-airline_code': 49, 'I-fare_basis_code': 50, 'B-depart_date.year': 51, 'B-period_of_day': 52, 'I-depart_time.time_relative': 53, 'I-depart_time.end_time': 54, 'I-economy': 55, 'B-aircraft_code': 56, 'B-arrive_time.time': 57, 'B-arrive_time.time_relative': 58, 'I-flight_mod': 59, 'B-depart_time.period_mod': 60, 'B-fromloc.airport_code': 61, 'B-flight_number': 62, 'B-flight_mod': 63, 'B-toloc.airport_name': 64, 'I-arrive_time.start_time': 65, 'B-days_code': 66, 'B-meal_description': 67, 'B-return_date.date_relative': 68, 'I-toloc.state_name': 69, 'I-restriction_code': 70, 'B-arrive_time.period_of_day': 71, 'B-airport_name': 72, 'I-fromloc.city_name': 73, 'I-time': 74, 'B-toloc.state_name': 75, 'I-city_name': 76, 'B-stoploc.airport_name': 77, 'B-toloc.country_name': 78, 'B-stoploc.state_code': 79, 'I-meal_description': 80, 'I-depart_date.day_number': 81, 'B-day_number': 82, 'I-flight_time': 83, 'I-depart_time.start_time': 84, 'B-return_date.month_name': 85, 'I-arrive_time.period_of_day': 86, 'B-restriction_code': 87, 'B-depart_date.date_relative': 88, 'B-arrive_time.start_time': 89, 'I-toloc.city_name': 90, 'I-arrive_time.end_time': 91, 'B-flight_stop': 92, 'I-return_date.date_relative': 93, 'B-depart_time.time': 94, 'B-fromloc.state_code': 95, 'B-flight_time': 96, 'B-return_time.period_of_day': 97, 'B-time_relative': 98, 'B-arrive_time.period_mod': 99, 'B-arrive_date.day_name': 100, 'I-toloc.airport_name': 101, 'B-depart_date.day_number': 102, 'I-stoploc.city_name': 103, 'I-class_type': 104, 'B-connect': 105, 'B-fare_amount': 106, 'I-depart_date.day_name': 107, 'I-transport_type': 108, 'B-arrive_date.date_relative': 109, 'I-flight_stop': 110, 'B-mod': 111, 'O': 112, 'B-economy': 113, 'I-depart_time.period_of_day': 114, 'I-fromloc.state_name': 115, 'B-airport_code': 116, 'B-today_relative': 117, 'B-flight_days': 118, 'B-city_name': 119, 'I-arrive_date.day_number': 120, 'B-airline_name': 121, 'B-month_name': 122, 'B-meal': 123, 'B-fromloc.state_name': 124, '<unk>': 1, '<pad>': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create reverse mapping"
      ],
      "metadata": {
        "id": "wJJEriNervOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_id={i:w for w,i in word_vocab.items()}\n",
        "intent_id={i:w for w,i in intent_vocab.items()}\n",
        "slot_id={i:w for w,i in slot_vocab.items()}\n",
        "print(vocab_id)\n",
        "print(intent_id)\n",
        "print(slot_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgtHRvTfr2M6",
        "outputId": "38d67b3a-fdf5-4d57-8a1b-c8565c13cba8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '<pad>', 1: '<unk>', 2: '7', 3: 'originate', 4: 'm', 5: 's', 6: '416', 7: 'companies', 8: 'some', 9: 'seventeenth', 10: '1000', 11: 'o', 12: '718', 13: 'ewr', 14: 'j31', 15: 'so', 16: '402', 17: 'q', 18: 'arrangements', 19: 'limousines', 20: 'repeat', 21: 'offers', 22: 'stands', 23: 'jfk', 24: 'georgia', 25: 'lastest', 26: 'expensive', 27: '420', 28: '1992', 29: 'or', 30: 'california', 31: 'names', 32: 'ninth', 33: 'options', 34: '838', 35: 'after', 36: '2', 37: 'eleventh', 38: 'thirty', 39: 'f28', 40: 'dfw', 41: 'following', 42: '1300', 43: '4', 44: 'francisco', 45: '1110', 46: 'michigan', 47: 'non', 48: 'now', 49: 'me', 50: 'off', 51: 'then', 52: 'transport', 53: 'used', 54: 'capacity', 55: 'landing', 56: 'arriving', 57: 'ff', 58: 'number', 59: 'texas', 60: 'sixteen', 61: '1130', 62: 'fit', 63: '257', 64: 'sorry', 65: 'world', 66: 'airport', 67: 'united', 68: '271', 69: 'detroit', 70: 'takes', 71: '539', 72: 'closest', 73: 'aa', 74: 'snack', 75: 'only', 76: '11', 77: '1220', 78: 'before', 79: '845', 80: 'able', 81: 'makes', 82: 'route', 83: 'seattle', 84: 'class', 85: 'salt', 86: 'nonstop', 87: 'weekday', 88: '823', 89: 'bound', 90: 'out', 91: 'take', 92: 'continental', 93: 'stapleton', 94: 'please', 95: 'without', 96: '1020', 97: 'up', 98: 'people', 99: 'under', 100: 'at', 101: '771', 102: 'rentals', 103: 'quebec', 104: 'anything', 105: 'washington', 106: '1222', 107: '137338', 108: 'fare', 109: 'much', 110: 'supper', 111: '201', 112: 'level', 113: 'saturday', 114: '1059', 115: 'abbreviations', 116: 'smallest', 117: '1600', 118: 'over', 119: 'stopping', 120: '727', 121: 'their', 122: 'includes', 123: 'into', 124: 'than', 125: 'across', 126: 'economic', 127: 'them', 128: 'august', 129: 'various', 130: 'soon', 131: 'general', 132: 'doesn', 133: 'connects', 134: 'thank', 135: 'flights', 136: 'ticket', 137: 'saturdays', 138: 'classes', 139: 'proper', 140: 'eighteenth', 141: 'preferably', 142: 'know', 143: 'as', 144: 'late', 145: 'weekdays', 146: '1205', 147: 'month', 148: 'arizona', 149: '300', 150: 'don', 151: '819', 152: 'listed', 153: 'has', 154: '130', 155: 'fine', 156: 'of', 157: 'like', 158: 'mco', 159: 'am', 160: 'december', 161: 'guardia', 162: 'nights', 163: '767', 164: '210', 165: 'days', 166: 'traveling', 167: 'next', 168: 'say', 169: 'need', 170: 'twentieth', 171: 'friends', 172: 'utah', 173: 'san', 174: 'northwest', 175: 'october', 176: '296', 177: 'again', 178: 'between', 179: 'services', 180: 'straight', 181: 'week', 182: 'tomorrow', 183: '106', 184: 'january', 185: 'via', 186: 'year', 187: 'cities', 188: 'atl', 189: 'night', 190: 'reverse', 191: 'lowest', 192: 'i', 193: 'newark', 194: 'day', 195: 'pennsylvania', 196: 'time', 197: '124', 198: 'being', 199: 'home', 200: 'airports', 201: 'nashville', 202: 'one', 203: 'using', 204: 'find', 205: 'service', 206: '10', 207: 'spend', 208: \"'t\", 209: 'belong', 210: 'fifteenth', 211: 'seating', 212: 'served', 213: 'reaches', 214: 'dallas', 215: 'monday', 216: 'eight', 217: \"o'clock\", 218: 'look', 219: '555', 220: 'afternoons', 221: 'restriction', 222: 'dinnertime', 223: 'today', 224: 'sometime', 225: 'intercontinental', 226: 'b', 227: '352', 228: 'm80', 229: '1940', 230: 'la', 231: 'airfare', 232: 'long', 233: \"'d\", 234: 'd10', 235: 'chicago', 236: 'colorado', 237: 'bring', 238: 'got', 239: 'an', 240: 'dl', 241: 'worth', 242: 'love', 243: '1200', 244: 'limousine', 245: 'starting', 246: 'want', 247: 'philadelphia', 248: 'takeoff', 249: 'possible', 250: 'milwaukee', 251: 'capacities', 252: '6', 253: 'offer', 254: 'airline', 255: 'have', 256: 'hi', 257: 'your', 258: 'rates', 259: '1288', 260: 'reaching', 261: 'twenty', 262: 'march', 263: 'fares', 264: 'tower', 265: '730', 266: 'carolina', 267: 'earliest', 268: 'thanks', 269: '1291', 270: 'well', 271: 'hello', 272: 'should', 273: 'usa', 274: 'largest', 275: 'sunday', 276: 'alaska', 277: 'economy', 278: 'to', 279: 'regarding', 280: 'live', 281: 'sixteenth', 282: 'return', 283: 'these', 284: '329', 285: 'do', 286: 'having', 287: 'meaning', 288: 'vegas', 289: 'planes', 290: 'determine', 291: 'still', 292: 'layover', 293: 'ls', 294: 'around', 295: 'mealtime', 296: '1245', 297: 'serve', 298: 'h', 299: '55', 300: 'maximum', 301: '645', 302: 'orlando', 303: 'inform', 304: 'put', 305: 'working', 306: 'kindly', 307: 'memphis', 308: 'we', 309: 'let', 310: 'scheduled', 311: 'by', 312: 'oh', 313: 'provides', 314: 'calling', 315: 'yyz', 316: 'thursday', 317: 'thereafter', 318: 'could', 319: 'fourteenth', 320: 'miami', 321: 'july', 322: '815', 323: 'start', 324: 'enroute', 325: 'show', 326: 'fifth', 327: 'jersey', 328: 'third', 329: 'also', 330: 'does', 331: 'twa', 332: 'they', 333: 'lives', 334: 'choices', 335: 'run', 336: 'noon', 337: 'four', 338: 'many', 339: '1145', 340: 'june', 341: '345', 342: 'serving', 343: '400', 344: 'car', 345: 'transportation', 346: '12', 347: 'if', 348: 'final', 349: 'place', 350: 'cover', 351: 'nationair', 352: 'come', 353: 'taking', 354: 'houston', 355: '428', 356: 'tickets', 357: 'heading', 358: 'most', 359: 'aircraft', 360: 'right', 361: 'delta', 362: 'departure', 363: '1039', 364: 'make', 365: 'explain', 366: 'yes', 367: 'including', 368: 'september', 369: 'cars', 370: 'during', 371: 'define', 372: 'laying', 373: 'cincinnati', 374: 'thing', 375: 'oak', 376: 'eastern', 377: 'local', 378: 'this', 379: 'indiana', 380: '4400', 381: 'minnesota', 382: 'dc10', 383: 'listings', 384: '928', 385: 'qx', 386: 'southwest', 387: 'burbank', 388: 'must', 389: '80', 390: 'bay', 391: '217', 392: 'lester', 393: '1055', 394: 'evening', 395: '110', 396: '163', 397: 'go', 398: 'hou', 399: 'f', 400: 'connection', 401: 'there', 402: 'seventeen', 403: 'trying', 404: 'november', 405: 'plan', 406: 'continent', 407: 'ap', 408: '5', 409: 'afterwards', 410: 'will', 411: 'on', 412: 'least', 413: 'thirteenth', 414: 'it', 415: 'denver', 416: 'looking', 417: 'who', 418: 'ontario', 419: 'ac', 420: 'besides', 421: 'ap57', 422: 'abbreviation', 423: '430', 424: 'going', 425: 'display', 426: 'phoenix', 427: '343', 428: 'atlanta', 429: 'ten', 430: 'daily', 431: 'can', 432: '324', 433: 'bwi', 434: 'continuing', 435: 'and', 436: 'sure', 437: 'schedule', 438: 'morning', 439: 'dulles', 440: 'listing', 441: '757', 442: 'offered', 443: 'ua', 444: 'passengers', 445: 'less', 446: 'database', 447: '1026', 448: '98', 449: 'while', 450: 'itinerary', 451: 'afternoon', 452: '934', 453: 'boeing', 454: 'ea', 455: 'bur', 456: 'twelfth', 457: '1700', 458: '269', 459: 'missouri', 460: 'breakfast', 461: 'such', 462: 'ord', 463: '3', 464: 'connections', 465: \"'hare\", 466: 'carried', 467: 'costs', 468: 'reservations', 469: '505', 470: 'twelve', 471: 'hours', 472: 'air', 473: 'field', 474: 'advertises', 475: 'leaving', 476: 'airfares', 477: '3357', 478: '405', 479: 'runs', 480: '737', 481: 'fn', 482: 'through', 483: 'york', 484: 'oakland', 485: 'zone', 486: 'be', 487: 'far', 488: 'too', 489: '1017', 490: 'see', 491: 'diego', 492: 'toward', 493: 'midwest', 494: 'discount', 495: 'leave', 496: 'county', 497: '445', 498: 'catch', 499: 'else', 500: '229', 501: 'yn', 502: 'lunch', 503: 'equipment', 504: 'canadian', 505: 'international', 506: '1115', 507: 'hartfield', 508: 'meals', 509: 'tuesdays', 510: 'prices', 511: 'may', 512: 'gets', 513: 'y', 514: 'any', 515: 'mitchell', 516: 'lufthansa', 517: 'sd', 518: 'lake', 519: 'second', 520: '1765', 521: 'mia', 522: '9', 523: 'those', 524: 'numbers', 525: 'both', 526: '139', 527: 'single', 528: 'book', 529: 'times', 530: 'taxi', 531: 'charges', 532: 'a', 533: 'february', 534: '1991', 535: 'requesting', 536: '515', 537: 'direct', 538: '630', 539: 'co', 540: 'question', 541: '650', 542: 'originating', 543: 'greatest', 544: 'available', 545: 'arrives', 546: 'stopovers', 547: 'flight', 548: 'currently', 549: 'tampa', 550: '150', 551: 'another', 552: 'concerning', 553: 'north', 554: 'indianapolis', 555: 'types', 556: 'nw', 557: 'cleveland', 558: 'charlotte', 559: '500', 560: 'once', 561: 'midnight', 562: '57', 563: '723', 564: 'restrictions', 565: 'help', 566: '311', 567: 'los', 568: 'kansas', 569: 'list', 570: 'land', 571: 'wednesday', 572: '0900', 573: 'first', 574: 'express', 575: '230', 576: '8', 577: '1209', 578: 'beach', 579: 'total', 580: 'code', 581: 'st.', 582: 'equal', 583: 'fifteen', 584: 'tacoma', 585: '305', 586: 'mean', 587: 'toronto', 588: 'nonstops', 589: 'along', 590: 'eighth', 591: '417', 592: 'qo', 593: 'approximately', 594: 'ground', 595: 'stop', 596: 'sa', 597: '746', 598: '734', 599: 'flies', 600: 'scenario', 601: \"'s\", 602: 'trip', 603: 'begins', 604: 'departing', 605: 'the', 606: 'instead', 607: 'try', 608: 'hopefully', 609: 'information', 610: 'represented', 611: 'travels', 612: 'schedules', 613: 'later', 614: 'limo', 615: 'overnight', 616: 'but', 617: 'philly', 618: '212', 619: 'buy', 620: '1133', 621: '733', 622: 'distance', 623: 'dollars', 624: '71', 625: 'transcontinental', 626: 'pearson', 627: 'town', 628: 'for', 629: 'paul', 630: 'nevada', 631: 'great', 632: 'reservation', 633: 'lax', 634: 'just', 635: 'wanted', 636: 'amount', 637: '2153', 638: 'landings', 639: 'very', 640: 'operation', 641: 'destination', 642: '270', 643: '1505', 644: 'longest', 645: '200', 646: 'april', 647: 'priced', 648: '1030', 649: 'dinner', 650: '1158', 651: '1', 652: 'pm', 653: 'fort', 654: 'prefer', 655: '281', 656: 'everywhere', 657: 'hold', 658: 'are', 659: '466', 660: \"'ve\", 661: 'get', 662: 'airplane', 663: '323', 664: 'rental', 665: 'sounds', 666: 'different', 667: 'montreal', 668: 'turboprop', 669: 'angeles', 670: '2100', 671: 'arrive', 672: '415', 673: 'sort', 674: 'plane', 675: '459', 676: 'with', 677: 'okay', 678: 'minneapolis', 679: 'beginning', 680: 'give', 681: 'locate', 682: 'red', 683: 'operating', 684: 'trans', 685: 'flying', 686: 'thursdays', 687: 'codes', 688: 'thirtieth', 689: 'summer', 690: 'meal', 691: 'logan', 692: 'is', 693: 'either', 694: 'depart', 695: '1024', 696: 'way', 697: '755', 698: '852', 699: 'how', 700: 'boston', 701: '100', 702: 'which', 703: 'sundays', 704: '1083', 705: 'anywhere', 706: 'dc', 707: 'cheapest', 708: 'connecting', 709: '810', 710: 'us', 711: 'actually', 712: 'seven', 713: '720', 714: 'mornings', 715: 'stopover', 716: '82', 717: 'tennessee', 718: 'minimum', 719: 'within', 720: 'you', 721: 'would', 722: 'booking', 723: 'bna', 724: '530', 725: '747', 726: 'here', 727: 'from', 728: 'travel', 729: \"'ll\", 730: 'planning', 731: 'nineteenth', 732: '1850', 733: '279', 734: 'uses', 735: 'westchester', 736: 'business', 737: 'round', 738: 'stops', 739: 'near', 740: 'provide', 741: 'ap68', 742: 'my', 743: '1500', 744: 'nighttime', 745: 'petersburg', 746: 'shortest', 747: 'visit', 748: 'new', 749: 'train', 750: 'downtown', 751: 'each', 752: 'repeating', 753: 'pittsburgh', 754: 'jet', 755: 'wish', 756: '3724', 757: 'cheap', 758: 'seat', 759: 'wants', 760: 'airlines', 761: 'louis', 762: 'what', 763: 'stand', 764: 'provided', 765: 'making', 766: 'in', 767: 'directly', 768: 'eye', 769: 'connect', 770: 'tuesday', 771: 'more', 772: 'd', 773: 'trips', 774: 'serviced', 775: 'arrange', 776: 'seats', 777: '19', 778: 'arrivals', 779: 'where', 780: 'cost', 781: 'use', 782: 'grounds', 783: 'describe', 784: 'city', 785: 'designate', 786: 'departs', 787: 'located', 788: 'baltimore', 789: 'whether', 790: 'latest', 791: 'canada', 792: 'mondays', 793: 'back', 794: 'symbols', 795: 'vicinity', 796: 'fly', 797: 'price', 798: 'las', 799: 'area', 800: '225', 801: 'tenth', 802: 'arrival', 803: 'leaves', 804: 'wednesdays', 805: '825', 806: 'goes', 807: 'fourth', 808: 'three', 809: 'close', 810: '21', 811: 'airplanes', 812: 'interested', 813: 'eleven', 814: 'inexpensive', 815: 'qualify', 816: 'date', 817: '43', 818: 'seventh', 819: 'thrift', 820: 'rent', 821: 'two', 822: 'west', 823: 'same', 824: 'highest', 825: '1993', 826: 'about', 827: '315', 828: '615', 829: 'hp', 830: 'order', 831: 'name', 832: 'american', 833: 'tonight', 834: 'ap80', 835: 'serves', 836: '72s', 837: 'returning', 838: 'midway', 839: '1045', 840: 'ohio', 841: 'difference', 842: 'early', 843: '1100', 844: '2134', 845: \"'m\", 846: 'jose', 847: '813', 848: 'no', 849: 'all', 850: '932', 851: 'kinds', 852: 'd9s', 853: 'other', 854: 'cp', 855: '1230', 856: 'kind', 857: 'noontime', 858: 'type', 859: 'six', 860: 'that', 861: 'florida', 862: 'sixth', 863: 'k', 864: 'coming', 865: \"'re\", 866: '73s', 867: '297', 868: 'iah', 869: 'last', 870: 'america', 871: 'sfo', 872: 'when', 873: '497766', 874: 'include', 875: 'staying', 876: 'lands', 877: 'takeoffs', 878: 'rate', 879: 'fridays', 880: 'tell', 881: 'coach', 882: 'somebody', 883: 'columbus', 884: 'departures', 885: 'friday', 886: 'carries', 887: 'earlier', 888: 'qw', 889: 'c', 890: '705'}\n",
            "{0: '<unk>', 1: 'airline+flight_no', 2: 'ground_service', 3: 'flight_time', 4: 'distance', 5: 'abbreviation', 6: 'restriction', 7: 'airport', 8: 'quantity', 9: 'meal', 10: 'flight_no', 11: 'airfare', 12: 'flight+airfare', 13: 'cheapest', 14: 'ground_service+ground_fare', 15: 'aircraft', 16: 'airline', 17: 'aircraft+flight+flight_no', 18: 'airfare+flight_time', 19: 'ground_fare', 20: 'city', 21: 'flight', 22: 'capacity'}\n",
            "{2: 'B-state_name', 3: 'B-class_type', 4: 'B-depart_date.today_relative', 5: 'B-depart_date.day_name', 6: 'B-toloc.airport_code', 7: 'I-airport_name', 8: 'B-return_date.today_relative', 9: 'B-meal_code', 10: 'I-arrive_time.time_relative', 11: 'B-return_date.day_number', 12: 'I-meal_code', 13: 'B-fare_basis_code', 14: 'B-day_name', 15: 'B-arrive_date.today_relative', 16: 'B-toloc.state_code', 17: 'I-arrive_time.time', 18: 'B-depart_time.end_time', 19: 'B-stoploc.city_name', 20: 'B-cost_relative', 21: 'B-depart_time.start_time', 22: 'B-round_trip', 23: 'I-cost_relative', 24: 'B-arrive_date.month_name', 25: 'B-arrive_time.end_time', 26: 'B-return_time.period_mod', 27: 'B-depart_time.time_relative', 28: 'I-round_trip', 29: 'B-fromloc.airport_name', 30: 'B-depart_time.period_of_day', 31: 'I-depart_time.time', 32: 'I-airline_name', 33: 'I-return_date.today_relative', 34: 'B-return_date.day_name', 35: 'I-depart_date.today_relative', 36: 'B-transport_type', 37: 'B-or', 38: 'B-depart_date.month_name', 39: 'I-fromloc.airport_name', 40: 'I-fare_amount', 41: 'B-state_code', 42: 'I-today_relative', 43: 'B-fromloc.city_name', 44: 'B-arrive_date.day_number', 45: 'B-time', 46: 'I-return_date.day_number', 47: 'I-mod', 48: 'B-toloc.city_name', 49: 'B-airline_code', 50: 'I-fare_basis_code', 51: 'B-depart_date.year', 52: 'B-period_of_day', 53: 'I-depart_time.time_relative', 54: 'I-depart_time.end_time', 55: 'I-economy', 56: 'B-aircraft_code', 57: 'B-arrive_time.time', 58: 'B-arrive_time.time_relative', 59: 'I-flight_mod', 60: 'B-depart_time.period_mod', 61: 'B-fromloc.airport_code', 62: 'B-flight_number', 63: 'B-flight_mod', 64: 'B-toloc.airport_name', 65: 'I-arrive_time.start_time', 66: 'B-days_code', 67: 'B-meal_description', 68: 'B-return_date.date_relative', 69: 'I-toloc.state_name', 70: 'I-restriction_code', 71: 'B-arrive_time.period_of_day', 72: 'B-airport_name', 73: 'I-fromloc.city_name', 74: 'I-time', 75: 'B-toloc.state_name', 76: 'I-city_name', 77: 'B-stoploc.airport_name', 78: 'B-toloc.country_name', 79: 'B-stoploc.state_code', 80: 'I-meal_description', 81: 'I-depart_date.day_number', 82: 'B-day_number', 83: 'I-flight_time', 84: 'I-depart_time.start_time', 85: 'B-return_date.month_name', 86: 'I-arrive_time.period_of_day', 87: 'B-restriction_code', 88: 'B-depart_date.date_relative', 89: 'B-arrive_time.start_time', 90: 'I-toloc.city_name', 91: 'I-arrive_time.end_time', 92: 'B-flight_stop', 93: 'I-return_date.date_relative', 94: 'B-depart_time.time', 95: 'B-fromloc.state_code', 96: 'B-flight_time', 97: 'B-return_time.period_of_day', 98: 'B-time_relative', 99: 'B-arrive_time.period_mod', 100: 'B-arrive_date.day_name', 101: 'I-toloc.airport_name', 102: 'B-depart_date.day_number', 103: 'I-stoploc.city_name', 104: 'I-class_type', 105: 'B-connect', 106: 'B-fare_amount', 107: 'I-depart_date.day_name', 108: 'I-transport_type', 109: 'B-arrive_date.date_relative', 110: 'I-flight_stop', 111: 'B-mod', 112: 'O', 113: 'B-economy', 114: 'I-depart_time.period_of_day', 115: 'I-fromloc.state_name', 116: 'B-airport_code', 117: 'B-today_relative', 118: 'B-flight_days', 119: 'B-city_name', 120: 'I-arrive_date.day_number', 121: 'B-airline_name', 122: 'B-month_name', 123: 'B-meal', 124: 'B-fromloc.state_name', 1: '<unk>', 0: '<pad>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1:Intent Classification"
      ],
      "metadata": {
        "id": "d8zIkd3voqtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation"
      ],
      "metadata": {
        "id": "_Rs9bCr-o1fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "class Intent_Dataset(Dataset):\n",
        "  def __init__(self,data,vocabulary,intent_list):\n",
        "    self.data=data\n",
        "    self.vocabulary=vocabulary\n",
        "    self.intent_list=intent_list\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,idx):\n",
        "    sentence=self.data[idx]\n",
        "    text=sentence[\"text\"]\n",
        "    intent=sentence[\"intent\"]\n",
        "    text_ids=[self.vocabulary.get(word,self.vocabulary['<unk>']) for word in text.split()]\n",
        "    intent_id=self.intent_list.get(intent,self.intent_list['<unk>'])\n",
        "    return{\n",
        "        \"text\":torch.tensor(text_ids,dtype=torch.long),\n",
        "        \"intent\":torch.tensor(intent_id,dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "KQBBCqwUoma9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collate function to pad the texts in a batch to match the same length"
      ],
      "metadata": {
        "id": "HMxDAgf1o7CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def intent_collate_fn(batch):\n",
        "  texts=[item[\"text\"] for item in batch]\n",
        "  intent=[item[\"intent\"] for item in batch]\n",
        "  padded_texts=pad_sequence(texts,batch_first=True,padding_value=0)\n",
        "  intent_stacked=torch.stack(intent)\n",
        "  return{\n",
        "      \"text\":padded_texts,\n",
        "      \"intent\":intent_stacked\n",
        "  }"
      ],
      "metadata": {
        "id": "A1KEf-D6o5O8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the train dataloader"
      ],
      "metadata": {
        "id": "23arHElBpAAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size=30\n",
        "intent_train_dataset=Intent_Dataset(train_data,word_vocab,intent_vocab)\n",
        "intent_train_loader=DataLoader(dataset=intent_train_dataset,batch_size=batch_size,shuffle=True,collate_fn=intent_collate_fn)"
      ],
      "metadata": {
        "id": "w9GMQg7HpAkR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of RNN for intent classification"
      ],
      "metadata": {
        "id": "Bxrm3gHgpC1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class Intent_RNN(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.input_to_hidden=nn.Linear(input_dim,hidden_dim)\n",
        "    self.hidden_to_hidden=nn.Linear(hidden_dim,hidden_dim)\n",
        "    self.activation=nn.Tanh()\n",
        "  def forward(self,data):\n",
        "    batch_size,seq_len,_=data.shape\n",
        "    outputs=[]\n",
        "    hidden=torch.zeros(batch_size,self.hidden_dim,device=device)\n",
        "    for i in range(seq_len):\n",
        "      input=data[:,i,:]\n",
        "      hidden=self.activation(self.input_to_hidden(input)+self.hidden_to_hidden(hidden))\n",
        "      outputs.append(hidden.unsqueeze(1))\n",
        "    return torch.cat(outputs,dim=1)"
      ],
      "metadata": {
        "id": "tBqv25nDpK_J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model for intent classifier"
      ],
      "metadata": {
        "id": "vnvz4gyDpq71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Intent_Classifier(nn.Module):\n",
        "  def __init__(self,vocab,vocab_size,embed_dim,padding_idx,hidden_dim,output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,embed_dim,padding_idx=padding_idx)\n",
        "    self.RNN=Intent_RNN(embed_dim,hidden_dim)\n",
        "    self.classification=nn.Linear(hidden_dim,output_dim)\n",
        "  def forward(self,data):\n",
        "    embedded=self.embedding(data)\n",
        "    hidden=self.RNN(embedded)\n",
        "    pooled_hidden = hidden.mean(dim=1)\n",
        "    output=self.classification(pooled_hidden)\n",
        "    return output"
      ],
      "metadata": {
        "id": "LdsfnI8UqMpO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if the device is cuda or cpu- cuda preferred for training"
      ],
      "metadata": {
        "id": "lQQdvV01qQTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC58oSFXqYXj",
        "outputId": "1b31ef4f-2570-4290-c9a9-9d1bbb9da525"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating models with user-defined parameters"
      ],
      "metadata": {
        "id": "3n_-I5QrqY74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(word_vocab)\n",
        "embed_dim=300\n",
        "padding_idx=word_vocab[\"<pad>\"]\n",
        "hidden_dim=256\n",
        "output_dim=len(intent_vocab)\n",
        "intent_model=Intent_Classifier(word_vocab,vocab_size,embed_dim,padding_idx,hidden_dim,output_dim)\n",
        "intent_model.to(device)\n",
        "print(intent_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-Rjkee0qbX0",
        "outputId": "c02e8096-69cb-4739-bef6-f9d84bd97415"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent_Classifier(\n",
            "  (embedding): Embedding(891, 300, padding_idx=0)\n",
            "  (RNN): Intent_RNN(\n",
            "    (input_to_hidden): Linear(in_features=300, out_features=256, bias=True)\n",
            "    (hidden_to_hidden): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (classification): Linear(in_features=256, out_features=23, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to train"
      ],
      "metadata": {
        "id": "R0BmsxxsqpLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_train(model,device,no_of_epochs,train_loader,optimizer,criterion,no_of_samples):\n",
        "  model.to(device)\n",
        "  for epoch in range(no_of_epochs):\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "    for batch in train_loader:\n",
        "      text_batch=batch[\"text\"].to(device)\n",
        "      label_batch=batch[\"intent\"].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      predictions=model(text_batch)\n",
        "      loss=criterion(predictions,label_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss+=loss.item()\n",
        "    avg_loss=total_loss/len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{no_of_epochs}, Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "SJ6pX_mbqrfB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling function to train"
      ],
      "metadata": {
        "id": "kwm_SZPcqwNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "intent_criterion=nn.CrossEntropyLoss()\n",
        "intent_optimizer=optim.Adam(intent_model.parameters(),lr=0.001)\n",
        "no_of_epochs=10\n",
        "intent_train(intent_model,device,no_of_epochs,intent_train_loader,intent_optimizer,intent_criterion,no_of_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo60Yjiuq8ZE",
        "outputId": "2729b56d-c9db-4e6a-cf54-5c2857ac25cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average Loss: 0.9528\n",
            "Epoch 2/10, Average Loss: 0.6629\n",
            "Epoch 3/10, Average Loss: 0.4924\n",
            "Epoch 4/10, Average Loss: 0.3988\n",
            "Epoch 5/10, Average Loss: 0.2898\n",
            "Epoch 6/10, Average Loss: 0.2594\n",
            "Epoch 7/10, Average Loss: 0.2615\n",
            "Epoch 8/10, Average Loss: 0.2195\n",
            "Epoch 9/10, Average Loss: 0.1821\n",
            "Epoch 10/10, Average Loss: 0.1496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test dataloader"
      ],
      "metadata": {
        "id": "DHsIkbrRq9SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_test_dataset=Intent_Dataset(test_data,word_vocab,intent_vocab)\n",
        "intent_test_loader=DataLoader(dataset=intent_test_dataset,batch_size=batch_size,shuffle=False,collate_fn=intent_collate_fn)"
      ],
      "metadata": {
        "id": "sRxOLaMSrAQK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to evaluate the model"
      ],
      "metadata": {
        "id": "BTw-b6aFrVHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_evaluation(model,device,test_loader):\n",
        "  model.eval()\n",
        "  total_correct = 0\n",
        "  total_samples=0\n",
        "  unknown_intent_id=0\n",
        "  unknown_labels_count=0\n",
        "  mismatches_to_print=0\n",
        "  not_flight=0\n",
        "  with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "      test_batches=batch['text'].to(device)\n",
        "      label_batches=batch['intent'].to(device)\n",
        "      predicted_labels=model(test_batches)\n",
        "      _, predicted_indices = torch.max(predicted_labels, dim=1)\n",
        "      total_correct += (predicted_indices == label_batches).sum().item()\n",
        "      total_samples+=label_batches.size(0)\n",
        "  print(total_correct)\n",
        "  print(total_samples)\n",
        "  accuracy = total_correct / total_samples\n",
        "  print(f\"\\nModel Accuracy on Test Data: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "6_a3yt4YrVgC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calling the evaluation function"
      ],
      "metadata": {
        "id": "DP6a37EMrY7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_evaluation(intent_model,device,intent_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuSAd45IrbLn",
        "outputId": "ad5f0c06-0a2e-4153-8854-587761de3253"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "791\n",
            "893\n",
            "\n",
            "Model Accuracy on Test Data: 88.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calling the inference function"
      ],
      "metadata": {
        "id": "APIsdSBrrdIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model,test_dataset,index,vocab_id,intent_id):\n",
        "  sample = test_dataset[index]\n",
        "  input_tensor=sample[\"text\"].unsqueeze(0).to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor)\n",
        "    predictions = logits.argmax(dim=-1)\n",
        "  predicted_labels = predictions.squeeze(0).cpu().tolist()\n",
        "  text_ids=sample['text'].tolist()\n",
        "  text_deciphered=[vocab_id[word_id] for word_id in text_ids]\n",
        "  print(\"The text is\",text_deciphered)\n",
        "  intent_deciphered=[intent_id[sample['intent'].item()]]\n",
        "  print(\"The true value of slot is\",intent_deciphered)\n",
        "  predicted_deciphered=[intent_id[predicted_labels]]\n",
        "  print(\"The predicted value of slot is\",predicted_deciphered)"
      ],
      "metadata": {
        "id": "yRTBAQzjri3m"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=1\n",
        "inference(intent_model,intent_test_dataset,index,vocab_id,intent_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0m-Sq71rjp5",
        "outputId": "dbaa7819-c8da-4fea-a67e-53a04c8846e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is ['on', 'april', 'first', 'i', 'need', 'a', 'ticket', 'from', 'tacoma', 'to', 'san', 'jose', 'departing', 'before', '7', 'am']\n",
            "The true value of slot is ['airfare']\n",
            "The predicted value of slot is ['flight_time']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SLOT Classification"
      ],
      "metadata": {
        "id": "FqTf24uVrnDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset function for slot filling"
      ],
      "metadata": {
        "id": "OhVFiXCDr-mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "class Slot_Dataset(Dataset):\n",
        "  def __init__(self,data,word_vocab,slot_vocab):\n",
        "    self.data=data\n",
        "    self.word_vocab=word_vocab\n",
        "    self.slot_vocab=slot_vocab\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,idx):\n",
        "    sentence=self.data['text'][idx]\n",
        "    slots=self.data['slots'][idx]\n",
        "    word_ids=[self.word_vocab.get(word,self.word_vocab['<unk>']) for word in sentence.split()]\n",
        "    slot_ids=[self.slot_vocab.get(slot,self.slot_vocab['<unk>']) for slot in slots.split()]\n",
        "    return{\n",
        "        \"text\":torch.tensor(word_ids,dtype=torch.long),\n",
        "        \"slots\":torch.tensor(slot_ids,dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "KeRZUUNhrpZT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collate function to pad text and slot within a batch to make the same length"
      ],
      "metadata": {
        "id": "0jxqjIqcsBXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def slot_collate_fn(batch):\n",
        "  text_batch=[item[\"text\"] for item in batch]\n",
        "  slot_batch=[item[\"slots\"] for item in batch]\n",
        "  padded_text=pad_sequence(text_batch,batch_first=True,padding_value=0)\n",
        "  padded_slots=pad_sequence(slot_batch,batch_first=True,padding_value=0)\n",
        "  return{\n",
        "      \"text\":padded_text,\n",
        "      \"slots\":padded_slots\n",
        "  }"
      ],
      "metadata": {
        "id": "a_Gbhg4mr9Az"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the dataloader"
      ],
      "metadata": {
        "id": "ESlHOcWzsK0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "slot_train_dataset=Slot_Dataset(train_data,word_vocab,slot_vocab)\n",
        "slot_train_loader=DataLoader(dataset=slot_train_dataset,batch_size=30,shuffle=True,collate_fn=slot_collate_fn)\n",
        "print(slot_train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XJJoqlHsNM2",
        "outputId": "c52b557d-d2ce-4383-ad0d-b57778f301e3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7bf743de3470>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN implementation for slot filling"
      ],
      "metadata": {
        "id": "PlvxiraJsjN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class SLotRNN(nn.Module):\n",
        "  def __init__(self,vocab_size,embedding_dim,hidden_dim,output_dim,padding_idx):\n",
        "    super().__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.embedding=nn.Embedding(vocab_size,embedding_dim,padding_idx=padding_idx)\n",
        "    self.input_layer=nn.Linear(embedding_dim,hidden_dim,bias=True)\n",
        "    self.hidden_layer=nn.Linear(hidden_dim,hidden_dim,bias=True)\n",
        "    self.activation=nn.Tanh()\n",
        "    self.output_layer=nn.Linear(hidden_dim,output_dim,bias=True)\n",
        "  def forward(self,data):\n",
        "    batch_size,seq_len=data.shape\n",
        "    embedded_data = self.embedding(data)\n",
        "    hidden_state=torch.zeros(batch_size,self.hidden_dim,device=data.device)\n",
        "    outputs = []\n",
        "    for t in range(seq_len):\n",
        "      input=embedded_data[:,t,:]\n",
        "      hidden_state=self.input_layer(input)+self.hidden_layer(hidden_state)\n",
        "      hidden_state=self.activation(hidden_state)\n",
        "      output=self.output_layer(hidden_state)\n",
        "      outputs.append(output.unsqueeze(1))\n",
        "    return torch.cat(outputs,dim=1)"
      ],
      "metadata": {
        "id": "4CWn9RsgslOE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if the device is cuda or cpu- cuda preferred for training"
      ],
      "metadata": {
        "id": "oAc3xZddsovv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "qHmD8sFpsq1D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the model with user-defined parameters"
      ],
      "metadata": {
        "id": "uxLiiF8Vssoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(word_vocab)\n",
        "embedding_dim=300\n",
        "hidden_dim=256\n",
        "output_dim=len(slot_vocab)\n",
        "padding_idx=slot_vocab[\"<pad>\"]\n",
        "slot_model=SLotRNN(vocab_size,embedding_dim,hidden_dim,output_dim,padding_idx)"
      ],
      "metadata": {
        "id": "p_0HS6KesvaW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to train the model"
      ],
      "metadata": {
        "id": "RJC0X_5Qs13q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slot_train(model,device,no_of_epochs,train_loader,optimizer,loss_fn,no_of_samples):\n",
        "  model.to(device)\n",
        "  no_of_epochs=10\n",
        "  for epochs in range(no_of_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "      text=batch['text'].to(device)\n",
        "      slots=batch['slots'].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      predictions=model(text)\n",
        "      loss=loss_fn(predictions.view(-1,predictions.shape[-1]),slots.view(-1))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss+=loss.item()\n",
        "    avg_loss=total_loss/no_of_samples\n",
        "    print(f\"Epoch {epochs+1}/{no_of_epochs}, Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "xmCwCKX3s32Q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "ylXhzekEs6uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "slot_pad_idx=0\n",
        "slot_criterion=nn.CrossEntropyLoss(ignore_index=slot_pad_idx)\n",
        "slot_optimizer=optim.Adam(slot_model.parameters(),lr=0.01)\n",
        "slot_train(slot_model,device,no_of_epochs,slot_train_loader,slot_optimizer,slot_criterion,no_of_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwTLpIyas8vY",
        "outputId": "c0517449-d28d-4aaa-a76a-e6574fb5eac1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Average Loss: 0.0106\n",
            "Epoch 2/10, Average Loss: 0.0042\n",
            "Epoch 3/10, Average Loss: 0.0034\n",
            "Epoch 4/10, Average Loss: 0.0030\n",
            "Epoch 5/10, Average Loss: 0.0034\n",
            "Epoch 6/10, Average Loss: 0.0027\n",
            "Epoch 7/10, Average Loss: 0.0025\n",
            "Epoch 8/10, Average Loss: 0.0027\n",
            "Epoch 9/10, Average Loss: 0.0027\n",
            "Epoch 10/10, Average Loss: 0.0028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating test_dataloader"
      ],
      "metadata": {
        "id": "PW8421ACtIek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "slot_test_dataset=Slot_Dataset(train_data,word_vocab,slot_vocab)\n",
        "slot_test_loader=DataLoader(dataset=slot_test_dataset,batch_size=30,shuffle=False,collate_fn=slot_collate_fn)\n",
        "print(slot_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9U8tR2TtKrk",
        "outputId": "cf145e04-4fe3-4c7d-a78a-c1d32b63693b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7bf743bc2d50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to evaluate"
      ],
      "metadata": {
        "id": "6ZJ9e_7MtY6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slot_evaluation(model,device,test_loader):\n",
        "  model.eval()\n",
        "  slot_pad_idx=0\n",
        "  total_correct=0\n",
        "  total_tokens=0\n",
        "  with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "      text=batch['text'].to(device)\n",
        "      slots=batch['slots'].to(device)\n",
        "      predictions=model(text)\n",
        "      pred_labels=predictions.argmax(dim=-1)\n",
        "      mask = (slots != slot_pad_idx)\n",
        "      total_correct+=((pred_labels==slots)& mask).sum().item()\n",
        "      total_tokens+= mask.sum().item()\n",
        "  accuracy = total_correct / total_tokens\n",
        "  print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "bM-TSEIJtZT_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling evaluation function"
      ],
      "metadata": {
        "id": "Kg7ciaBetbub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slot_evaluation(slot_model,device,slot_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olleavmqtdte",
        "outputId": "2d7d8394-d19e-41af-da04-5beacf9e9ad3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference function"
      ],
      "metadata": {
        "id": "vvVuwbmctgrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slot_inference(model,test_dataset,index,vocab_id,slot_id):\n",
        "  sample = test_dataset[index]\n",
        "  input_tensor = sample[\"text\"].unsqueeze(0).to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor)\n",
        "    predictions = logits.argmax(dim=-1)\n",
        "  predicted_labels = predictions.squeeze(0).cpu().tolist()\n",
        "  text_ids=sample['text'].tolist()\n",
        "  text_deciphered=[vocab_id[word_id] for word_id in text_ids]\n",
        "  print(\"The text is\",text_deciphered)\n",
        "  slot_ids=sample['slots'].tolist()\n",
        "  slot_deciphered=[slot_id[word_id] for word_id in slot_ids]\n",
        "  print(\"The true value of slot is\",slot_deciphered)\n",
        "  predicted_deciphered=[slot_id[word_id] for word_id in predicted_labels]\n",
        "  print(\"The predicted value of slot is\",predicted_deciphered)"
      ],
      "metadata": {
        "id": "cEuHgwXttioo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calling inference"
      ],
      "metadata": {
        "id": "2bLdweUmtlCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index=2\n",
        "slot_inference(slot_model,slot_test_dataset,index,vocab_id,slot_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ybjcdH0tonq",
        "outputId": "9b3061b3-e7d4-4d7c-ea4c-861ac506d93a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is ['what', 'is', 'the', 'arrival', 'time', 'in', 'san', 'francisco', 'for', 'the', '755', 'am', 'flight', 'leaving', 'washington']\n",
            "The true value of slot is ['O', 'O', 'O', 'B-flight_time', 'I-flight_time', 'O', 'B-fromloc.city_name', 'I-fromloc.city_name', 'O', 'O', 'B-depart_time.time', 'I-depart_time.time', 'O', 'O', 'B-fromloc.city_name']\n",
            "The predicted value of slot is ['O', 'O', 'O', 'B-flight_time', 'I-flight_time', 'O', 'B-toloc.city_name', 'I-stoploc.city_name', 'O', 'O', 'B-depart_time.time', 'I-depart_time.time', 'O', 'O', 'B-fromloc.city_name']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slot-To-Intent"
      ],
      "metadata": {
        "id": "XonrDOh4ty7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to get the predicted labels of slot based on text"
      ],
      "metadata": {
        "id": "5vS5SdRgt7ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slot_pred(model,sentence):\n",
        "  input_tensor = sentence.unsqueeze(0).to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor)\n",
        "    predictions = logits.argmax(dim=-1)\n",
        "  predicted_labels = predictions.squeeze(0).cpu().tolist()\n",
        "  return predicted_labels"
      ],
      "metadata": {
        "id": "kCaxhbept4eg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset creation including predicted slot values"
      ],
      "metadata": {
        "id": "qJd168n3uB9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class Slot_to_Intent_Dataset(Dataset):\n",
        "  def __init__(self,data,model,word_vocab,intent_vocab):\n",
        "    self.data=data\n",
        "    self.word_vocab=word_vocab\n",
        "    self.intent_vocab=intent_vocab\n",
        "    self.slot_vocab=slot_vocab\n",
        "    self.model=model\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,idx):\n",
        "    sentence=self.data['text'][idx]\n",
        "    intent=self.data['intent'][idx]\n",
        "    text_ids=[self.word_vocab.get(word,self.word_vocab['<unk>']) for word in sentence.split()]\n",
        "    intent_id=self.intent_vocab.get(intent,self.intent_vocab['<unk>'])\n",
        "    text_tensor = torch.tensor(text_ids, dtype=torch.long)\n",
        "    slot_predicted_ids=slot_pred(self.model,text_tensor)\n",
        "    return{\n",
        "        \"text\":torch.tensor(text_ids,dtype=torch.long),\n",
        "        \"intent\":torch.tensor(intent_id,dtype=torch.long),\n",
        "        \"slot\":torch.tensor(slot_predicted_ids,dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "xEVwBbQLt_bt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collate function"
      ],
      "metadata": {
        "id": "pk_x_NUEuUDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def slot_to_intent_collate_fn(batch):\n",
        "  texts=[item[\"text\"] for item in batch]\n",
        "  intent=[item[\"intent\"] for item in batch]\n",
        "  slot=[item[\"slot\"] for item in batch]\n",
        "  padded_texts=pad_sequence(texts,batch_first=True,padding_value=0)\n",
        "  padded_slots=pad_sequence(slot,batch_first=True,padding_value=0)\n",
        "  intent_stacked=torch.stack(intent)\n",
        "  return{\n",
        "      \"text\":padded_texts,\n",
        "      \"intent\":intent_stacked,\n",
        "      \"slot\":padded_slots\n",
        "  }"
      ],
      "metadata": {
        "id": "RcQUWNHRuIKm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating dataloader and dataset"
      ],
      "metadata": {
        "id": "M1TWyfyUwfzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size=30\n",
        "slot_to_intent_train_dataset=Slot_to_Intent_Dataset(train_data,slot_model,word_vocab,intent_vocab)\n",
        "slot_to_intent_train_loader=DataLoader(dataset=slot_to_intent_train_dataset,batch_size=batch_size,shuffle=True,collate_fn=slot_to_intent_collate_fn)"
      ],
      "metadata": {
        "id": "3DWvnk9EuLC0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating models"
      ],
      "metadata": {
        "id": "-aC6JksZwnbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class Slot_to_Intent_RNN(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.input_to_hidden=nn.Linear(input_dim,hidden_dim)\n",
        "    self.hidden_to_hidden=nn.Linear(hidden_dim,hidden_dim)\n",
        "    self.activation=nn.Tanh()\n",
        "  def forward(self,data):\n",
        "    outputs=[]\n",
        "    batch_size,seq_len,_=data.shape\n",
        "    hidden=torch.zeros(batch_size,self.hidden_dim,device=device)\n",
        "    for i in range(seq_len):\n",
        "      input=data[:,i,:]\n",
        "      hidden=self.activation(self.input_to_hidden(input)+self.hidden_to_hidden(hidden))\n",
        "      outputs.append(hidden.unsqueeze(1))\n",
        "    return torch.cat(outputs,dim=1)"
      ],
      "metadata": {
        "id": "Re7Koog8wY3a"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SLot_to_Intent_Classifier(nn.Module):\n",
        "  def __init__(self,vocab,vocab_size,embed_dim,padding_idx,hidden_dim,output_dim,slot_vocab_size,slot_embed_dim,slot_padding_idx):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,embed_dim,padding_idx=padding_idx)\n",
        "    self.RNN=Slot_to_Intent_RNN(embed_dim,hidden_dim)\n",
        "    self.classification=nn.Linear(hidden_dim+slot_embed_dim,output_dim)\n",
        "    self.slot_embedding = nn.Embedding(slot_vocab_size, slot_embed_dim, padding_idx=slot_padding_idx)\n",
        "  def forward(self,data,slot_pred):\n",
        "    embedded=self.embedding(data)\n",
        "    hidden=self.RNN(embedded)\n",
        "    slot_embeds = self.slot_embedding(slot_pred)\n",
        "    slot_features = slot_embeds.mean(dim=1)\n",
        "    pooled_hidden = hidden.mean(dim=1)\n",
        "    combined = torch.cat([pooled_hidden, slot_features], dim=1)\n",
        "    output=self.classification(combined)\n",
        "    return output"
      ],
      "metadata": {
        "id": "-nbN5XLT1KB2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating model with user-defined parameters"
      ],
      "metadata": {
        "id": "Vrs7CAkB1MYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(word_vocab)\n",
        "slot_vocab_size=len(slot_vocab)\n",
        "slot_embed_dim=32\n",
        "slot_padding_idx=0\n",
        "embed_dim=300\n",
        "padding_idx=word_vocab[\"<pad>\"]\n",
        "hidden_dim=256\n",
        "output_dim=len(intent_vocab)\n",
        "slot_to_intent_model=SLot_to_Intent_Classifier(word_vocab,vocab_size,embed_dim,padding_idx,hidden_dim,output_dim,slot_vocab_size,slot_embed_dim,slot_padding_idx)\n",
        "slot_to_intent_model.to(device)\n",
        "print(slot_to_intent_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ooV29_n1QNY",
        "outputId": "12a44b26-9943-44f7-f429-9601a9ee8322"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLot_to_Intent_Classifier(\n",
            "  (embedding): Embedding(891, 300, padding_idx=0)\n",
            "  (RNN): Slot_to_Intent_RNN(\n",
            "    (input_to_hidden): Linear(in_features=300, out_features=256, bias=True)\n",
            "    (hidden_to_hidden): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (classification): Linear(in_features=288, out_features=23, bias=True)\n",
            "  (slot_embedding): Embedding(125, 32, padding_idx=0)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train function"
      ],
      "metadata": {
        "id": "04YUHqy81h0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slot_to_intent_train(model,device,no_of_epochs,train_loader,optimizer,criterion,no_of_samples):\n",
        "  model.to(device)\n",
        "  for epoch in range(no_of_epochs):\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "    for batch in train_loader:\n",
        "      text_batch=batch[\"text\"].to(device)\n",
        "      label_batch=batch[\"intent\"].to(device)\n",
        "      slot_batch=batch[\"slot\"].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      predictions=model(text_batch,slot_batch)\n",
        "      loss=criterion(predictions,label_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss+=loss.item()\n",
        "    avg_loss=total_loss/len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{no_of_epochs}, Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "UHSTaAqf1f6D"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calling the train function"
      ],
      "metadata": {
        "id": "87V-Hz8l1nBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "slot_to_intent_criterion=nn.CrossEntropyLoss()\n",
        "slot_to_intent_optimizer=optim.Adam(slot_to_intent_model.parameters(),lr=0.001)\n",
        "no_of_epochs=10\n",
        "no_of_samples=len(train_data)\n",
        "print(no_of_samples)\n",
        "slot_to_intent_train(slot_to_intent_model,device, no_of_epochs, slot_to_intent_train_loader, slot_to_intent_optimizer, slot_to_intent_criterion, no_of_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQqfMoP11kC4",
        "outputId": "3eb611d5-b68d-481b-8747-25a663bd5d8d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4978\n",
            "Epoch 1/10, Average Loss: 0.9389\n",
            "Epoch 2/10, Average Loss: 0.5385\n",
            "Epoch 3/10, Average Loss: 0.4842\n",
            "Epoch 4/10, Average Loss: 0.3977\n",
            "Epoch 5/10, Average Loss: 0.2907\n",
            "Epoch 6/10, Average Loss: 0.3218\n",
            "Epoch 7/10, Average Loss: 0.2939\n",
            "Epoch 8/10, Average Loss: 0.3168\n",
            "Epoch 9/10, Average Loss: 0.2032\n",
            "Epoch 10/10, Average Loss: 0.1496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test dataloader"
      ],
      "metadata": {
        "id": "Ec9JknW110Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slot_to_intent_test_dataset=Slot_to_Intent_Dataset(test_data,slot_model,word_vocab,intent_vocab)\n",
        "slot_to_intent_test_loader=DataLoader(dataset=slot_to_intent_test_dataset,batch_size=batch_size,shuffle=True,collate_fn=slot_to_intent_collate_fn)"
      ],
      "metadata": {
        "id": "XlbOWMzy1x2c"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation function"
      ],
      "metadata": {
        "id": "pxUFKTkv17k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slot_to_intent_evaluation(model,device,test_loader):\n",
        "  model.eval()\n",
        "  total_correct = 0\n",
        "  total_samples=0\n",
        "  unknown_intent_id=0\n",
        "  unknown_labels_count=0\n",
        "  mismatches_to_print=0\n",
        "  not_flight=0\n",
        "  with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "      test_batches=batch['text'].to(device)\n",
        "      label_batches=batch['intent'].to(device)\n",
        "      slot_batches=batch['slot'].to(device)\n",
        "      predicted_labels=model(test_batches,slot_batches)\n",
        "      _, predicted_indices = torch.max(predicted_labels, dim=1)\n",
        "      total_correct += (predicted_indices == label_batches).sum().item()\n",
        "      total_samples+=label_batches.size(0)\n",
        "  print(total_correct)\n",
        "  print(total_samples)\n",
        "  accuracy = total_correct / total_samples\n",
        "  print(f\"\\nModel Accuracy on Test Data: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "uWi9YiA612AZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slot_to_intent_evaluation(slot_to_intent_model,device,slot_to_intent_test_loader)"
      ],
      "metadata": {
        "id": "nGxF1oPL17BZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47bc1a45-54f1-4cdf-fb5d-c056d0f3b099"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "799\n",
            "893\n",
            "\n",
            "Model Accuracy on Test Data: 89.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference function"
      ],
      "metadata": {
        "id": "_x-tWxOc2KVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slot_to_inference(model,test_dataset,index,vocab_id,intent_id):\n",
        "  sample = test_dataset[index]\n",
        "  input_tensor=sample[\"text\"].unsqueeze(0).to(device)\n",
        "  slot_tensor=sample[\"slot\"].unsqueeze(0).to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor,slot_tensor)\n",
        "    predictions = logits.argmax(dim=-1)\n",
        "  predicted_labels = predictions.squeeze(0).cpu().tolist()\n",
        "  text_ids=sample['text'].tolist()\n",
        "  text_deciphered=[vocab_id[word_id] for word_id in text_ids]\n",
        "  print(\"The text is\",text_deciphered)\n",
        "  intent_deciphered=[intent_id[sample['intent'].item()]]\n",
        "  print(\"The true value of slot is\",intent_deciphered)\n",
        "  predicted_deciphered=[intent_id[predicted_labels]]\n",
        "  print(\"The predicted value of slot is\",predicted_deciphered)"
      ],
      "metadata": {
        "id": "JKKWYD0C2GOD"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=1\n",
        "slot_to_inference(slot_to_intent_model,slot_to_intent_test_dataset,index,vocab_id,intent_id)"
      ],
      "metadata": {
        "id": "KDFbSaqn2MSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bb385b-9851-42f4-b597-225779cf1b76"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is ['on', 'april', 'first', 'i', 'need', 'a', 'ticket', 'from', 'tacoma', 'to', 'san', 'jose', 'departing', 'before', '7', 'am']\n",
            "The true value of slot is ['airfare']\n",
            "The predicted value of slot is ['airfare']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent to Slot"
      ],
      "metadata": {
        "id": "5LaVFNWa2PKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to get the predicted labels of slot based on text"
      ],
      "metadata": {
        "id": "JQhyCTQb4vUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_pred(model,sentence):\n",
        "  input_tensor=sentence.unsqueeze(0).to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor)\n",
        "    predictions = logits.argmax(dim=-1)\n",
        "  predicted_labels = predictions.squeeze(0).cpu().tolist()\n",
        "  return predicted_labels"
      ],
      "metadata": {
        "id": "CJwyW9RA2RI0"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Creation"
      ],
      "metadata": {
        "id": "9mjoSkUk4ybc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class Intent_to_Slot_Dataset(Dataset):\n",
        "  def __init__(self,data,model,word_vocab,slot_vocab):\n",
        "    self.data=data\n",
        "    self.word_vocab=word_vocab\n",
        "    self.slot_vocab=slot_vocab\n",
        "    self.model=model\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,idx):\n",
        "    sentence=self.data['text'][idx]\n",
        "    slots=self.data['slots'][idx]\n",
        "    text_ids=[self.word_vocab.get(word,self.word_vocab['<unk>']) for word in sentence.split()]\n",
        "    slot_ids=[self.slot_vocab.get(slot,self.slot_vocab['<unk>']) for slot in slots.split()]\n",
        "    text_tensor = torch.tensor(text_ids, dtype=torch.long)\n",
        "    slot_tensor=torch.tensor(slot_ids,dtype=torch.long)\n",
        "    intent_pred_ids=intent_pred(self.model,text_tensor)\n",
        "    intent_tensor=torch.tensor(intent_pred_ids, dtype=torch.long)\n",
        "    return{\n",
        "        \"text\":text_tensor,\n",
        "        \"intent\":intent_tensor,\n",
        "        \"slot\":slot_tensor\n",
        "    }"
      ],
      "metadata": {
        "id": "92E844Y04v-9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collate function"
      ],
      "metadata": {
        "id": "TbSsXWsl436i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def intent_to_slot_collate_fn(batch):\n",
        "  texts=[item[\"text\"] for item in batch]\n",
        "  intent=[item[\"intent\"] for item in batch]\n",
        "  slot=[item[\"slot\"] for item in batch]\n",
        "  padded_texts=pad_sequence(texts,batch_first=True,padding_value=0)\n",
        "  padded_slots=pad_sequence(slot,batch_first=True,padding_value=0)\n",
        "  intent_stacked=torch.stack(intent)\n",
        "  return{\n",
        "      \"text\":padded_texts,\n",
        "      \"intent\":intent_stacked,\n",
        "      \"slot\":padded_slots\n",
        "  }"
      ],
      "metadata": {
        "id": "_aQkWN3X40nP"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader creation"
      ],
      "metadata": {
        "id": "cadlSq5Z48-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size=30\n",
        "intent_to_slot_train_dataset=Intent_to_Slot_Dataset(train_data,intent_model,word_vocab,slot_vocab)\n",
        "intent_to_slot_train_loader=DataLoader(dataset=intent_to_slot_train_dataset,batch_size=batch_size,shuffle=True,collate_fn=intent_to_slot_collate_fn)"
      ],
      "metadata": {
        "id": "sDwoR1pA46Hc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification model"
      ],
      "metadata": {
        "id": "rmMlZ66W5Dz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class Intent_to_slot(nn.Module):\n",
        "  def __init__(self,vocab_size,embedding_dim,hidden_dim,output_dim,padding_idx,intent_embed_dim,intent_vocab_size):\n",
        "    super().__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.embedding=nn.Embedding(vocab_size,embedding_dim,padding_idx=padding_idx)\n",
        "    self.input_layer=nn.Linear(embedding_dim,hidden_dim,bias=True)\n",
        "    self.hidden_layer=nn.Linear(hidden_dim,hidden_dim,bias=True)\n",
        "    self.intent_embedding = nn.Embedding(intent_vocab_size, intent_embed_dim)\n",
        "    self.activation=nn.Tanh()\n",
        "    self.output_layer=nn.Linear(hidden_dim+intent_embed_dim,output_dim,bias=True)\n",
        "  def forward(self,data,intent):\n",
        "    batch_size,seq_len=data.shape\n",
        "    embedded_data = self.embedding(data)\n",
        "    hidden_state=torch.zeros(batch_size,self.hidden_dim,device=data.device)\n",
        "    outputs = []\n",
        "    intent_embed = self.intent_embedding(intent)\n",
        "    for t in range(seq_len):\n",
        "      input=embedded_data[:,t,:]\n",
        "      hidden_state=self.input_layer(input)+self.hidden_layer(hidden_state)\n",
        "      hidden_state=self.activation(hidden_state)\n",
        "      combined = torch.cat([hidden_state, intent_embed], dim=1)\n",
        "      output=self.output_layer(combined)\n",
        "      outputs.append(output.unsqueeze(1))\n",
        "    return torch.cat(outputs,dim=1)"
      ],
      "metadata": {
        "id": "aZI_ymnQ5Aqa"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating model with user-defined parameters"
      ],
      "metadata": {
        "id": "mMsJ4DLU5oEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(word_vocab)\n",
        "embedding_dim=300\n",
        "hidden_dim=256\n",
        "output_dim=len(slot_vocab)\n",
        "padding_idx=0\n",
        "intent_embed_dim=32\n",
        "intent_vocab_size=len(intent_vocab)\n",
        "intent_to_slot_model=Intent_to_slot(vocab_size,embedding_dim,hidden_dim,output_dim,padding_idx,intent_embed_dim,intent_vocab_size)\n",
        "intent_to_slot_model.to(device)\n",
        "print(intent_to_slot_model)"
      ],
      "metadata": {
        "id": "CXWFU9yQ5lcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8892ea81-990a-40a9-c194-3e6f30d437f9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent_to_slot(\n",
            "  (embedding): Embedding(891, 300, padding_idx=0)\n",
            "  (input_layer): Linear(in_features=300, out_features=256, bias=True)\n",
            "  (hidden_layer): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (intent_embedding): Embedding(23, 32)\n",
            "  (activation): Tanh()\n",
            "  (output_layer): Linear(in_features=288, out_features=125, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training function"
      ],
      "metadata": {
        "id": "upoAD36c5vVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_to_slot_train(model,device,no_of_epochs,train_loader,optimizer,loss_fn,no_of_samples):\n",
        "  model.to(device)\n",
        "  for epochs in range(no_of_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "      text=batch['text'].to(device)\n",
        "      intent=batch['intent'].to(device)\n",
        "      slots=batch['slot'].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      predictions=model(text,intent)\n",
        "      loss=loss_fn(predictions.view(-1,predictions.shape[-1]),slots.view(-1))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss+=loss.item()\n",
        "    avg_loss=total_loss/no_of_samples\n",
        "    print(f\"Epoch {epochs+1}/{no_of_epochs}, Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "TrNwiEQe5sZB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "slot_pad_idx=slot_vocab[\"<pad>\"]\n",
        "intent_to_slot_criterion=nn.CrossEntropyLoss(ignore_index=slot_pad_idx)\n",
        "intent_to_slot_optimizer=optim.Adam(intent_to_slot_model.parameters(),lr=0.01)\n",
        "no_of_epochs=10\n",
        "no_of_samples=len(train_data)\n",
        "print(no_of_samples)\n",
        "intent_to_slot_train(intent_to_slot_model,device,no_of_epochs,intent_to_slot_train_loader, intent_to_slot_optimizer,intent_to_slot_criterion, no_of_samples)"
      ],
      "metadata": {
        "id": "jcEHW-9m5xZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807b9013-7cd5-4de6-9a4c-5787b4c19a99"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4978\n",
            "Epoch 1/10, Average Loss: 0.0050\n",
            "Epoch 2/10, Average Loss: 0.0037\n",
            "Epoch 3/10, Average Loss: 0.0029\n",
            "Epoch 4/10, Average Loss: 0.0030\n",
            "Epoch 5/10, Average Loss: 0.0027\n",
            "Epoch 6/10, Average Loss: 0.0027\n",
            "Epoch 7/10, Average Loss: 0.0031\n",
            "Epoch 8/10, Average Loss: 0.0031\n",
            "Epoch 9/10, Average Loss: 0.0031\n",
            "Epoch 10/10, Average Loss: 0.0031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test dataloader"
      ],
      "metadata": {
        "id": "ZCVxYnb656gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_to_slot_test_dataset=Intent_to_Slot_Dataset(test_data,intent_model,word_vocab,slot_vocab)\n",
        "intent_to_slot_test_loader=DataLoader(dataset=intent_to_slot_test_dataset,batch_size=batch_size,shuffle=True,collate_fn=intent_to_slot_collate_fn)"
      ],
      "metadata": {
        "id": "Fj4eXCh654NV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation function"
      ],
      "metadata": {
        "id": "nzTqJMMe6MYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_to_slot_evaluation(model,device,test_loader):\n",
        "  model.eval()\n",
        "  slot_pad_idx=0\n",
        "  total_correct=0\n",
        "  total_tokens=0\n",
        "  with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "      text=batch['text'].to(device)\n",
        "      intent=batch['intent'].to(device)\n",
        "      slots=batch['slot'].to(device)\n",
        "      predictions=model(text,intent)\n",
        "      pred_labels=predictions.argmax(dim=-1)\n",
        "      mask = (slots != slot_pad_idx)\n",
        "      total_correct+=((pred_labels==slots)& mask).sum().item()\n",
        "      total_tokens+= mask.sum().item()\n",
        "  accuracy = total_correct / total_tokens\n",
        "  print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "9h0Pb8Lm58hJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intent_to_slot_evaluation(intent_to_slot_model,device,intent_to_slot_test_loader)"
      ],
      "metadata": {
        "id": "xd46QYpu6ApN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d6a2c7-e5ed-46ef-ca85-720b01f7cfb3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 95.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intent-to-Slot inference"
      ],
      "metadata": {
        "id": "OY-hyL6t6O2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_to_slot_inference(model,test_dataset,index,vocab_id,slot_id):\n",
        "  sample = test_dataset[index]\n",
        "  input_tensor = sample[\"text\"].unsqueeze(0).to(device)\n",
        "  intent_tensor=sample['intent'].unsqueeze(0).to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor,intent_tensor)\n",
        "    predictions = logits.argmax(dim=-1)\n",
        "  predicted_labels = predictions.squeeze(0).cpu().tolist()\n",
        "  text_ids=sample['text'].tolist()\n",
        "  text_deciphered=[vocab_id[word_id] for word_id in text_ids]\n",
        "  print(\"The text is\",text_deciphered)\n",
        "  slot_ids=sample['slot'].tolist()\n",
        "  slot_deciphered=[slot_id[word_id] for word_id in slot_ids]\n",
        "  print(\"The true value of slot is\",slot_deciphered)\n",
        "  predicted_deciphered=[slot_id[word_id] for word_id in predicted_labels]\n",
        "  print(\"The predicted value of slot is\",predicted_deciphered)"
      ],
      "metadata": {
        "id": "HvMVfRBy6Fq6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=2\n",
        "intent_to_slot_inference(intent_to_slot_model,intent_to_slot_test_dataset,index,vocab_id,slot_id)"
      ],
      "metadata": {
        "id": "AFm9NLun6LIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf9dcc4-d73a-4b44-89ff-d132cf14fa99"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is ['on', 'april', 'first', 'i', 'need', 'a', 'flight', 'going', 'from', 'phoenix', 'to', 'san', 'diego']\n",
            "The true value of slot is ['O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name']\n",
            "The predicted value of slot is ['O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joint-Model"
      ],
      "metadata": {
        "id": "vIsNKo6L6W4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Creation"
      ],
      "metadata": {
        "id": "v1uDcZqF6b-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "class Joint_Dataset(Dataset):\n",
        "  def __init__(self,data,word_vocab,slot_vocab,intent_vocab):\n",
        "    self.data=data\n",
        "    self.word_vocab=word_vocab\n",
        "    self.slot_vocab=slot_vocab\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,idx):\n",
        "    sentence=self.data['text'][idx]\n",
        "    slots=self.data['slots'][idx]\n",
        "    intent=self.data['intent'][idx]\n",
        "    word_ids=[self.word_vocab.get(word,self.word_vocab['<unk>']) for word in sentence.split()]\n",
        "    slot_ids=[self.slot_vocab.get(slot,self.slot_vocab['<unk>']) for slot in slots.split()]\n",
        "    intent_id=intent_vocab.get(intent,intent_vocab['<unk>'])\n",
        "    return{\n",
        "        \"text\":torch.tensor(word_ids,dtype=torch.long),\n",
        "        \"slots\":torch.tensor(slot_ids,dtype=torch.long),\n",
        "        \"intent\":torch.tensor(intent_id,dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "XtMQOcf06YjL"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "collate function"
      ],
      "metadata": {
        "id": "er_mIeQe6iPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def joint_collate_fn(batch):\n",
        "  text_batch=[item[\"text\"] for item in batch]\n",
        "  slot_batch=[item[\"slots\"] for item in batch]\n",
        "  intent_batch=[item[\"intent\"] for item in batch]\n",
        "  padded_text=pad_sequence(text_batch,batch_first=True,padding_value=0)\n",
        "  padded_slots=pad_sequence(slot_batch,batch_first=True,padding_value=0)\n",
        "  intent=torch.stack(intent_batch)\n",
        "  return{\n",
        "      \"text\":padded_text,\n",
        "      \"slots\":padded_slots,\n",
        "      \"intent\":intent\n",
        "  }"
      ],
      "metadata": {
        "id": "AcH7xwfP6bEt"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train dataloader"
      ],
      "metadata": {
        "id": "9a1l7Cis6mma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size=30\n",
        "joint_train_dataset=Joint_Dataset(train_data,word_vocab,slot_vocab,intent_vocab)\n",
        "joint_train_loader=DataLoader(dataset=joint_train_dataset,batch_size=batch_size,shuffle=True,collate_fn=joint_collate_fn)"
      ],
      "metadata": {
        "id": "Di01awMk6jvn"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model creation"
      ],
      "metadata": {
        "id": "vU5n546d6vtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class JointRnn(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.input_to_hidden=nn.Linear(input_dim,hidden_dim)\n",
        "    self.hidden_to_hidden=nn.Linear(hidden_dim,hidden_dim)\n",
        "    self.activation=nn.Tanh()\n",
        "  def forward(self,data):\n",
        "    batch_size,seq_len,_=data.size()\n",
        "    outputs=[]\n",
        "    hidden=torch.zeros(batch_size, self.hidden_dim, device=data.device)\n",
        "    for i in range(seq_len):\n",
        "      input=data[:,i,:]\n",
        "      hidden=self.activation(self.input_to_hidden(input)+self.hidden_to_hidden(hidden))\n",
        "      outputs.append(hidden.unsqueeze(1))\n",
        "    return torch.cat(outputs, dim=1)"
      ],
      "metadata": {
        "id": "X8XrP_GB6oGc"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Joint_Model(nn.Module):\n",
        "  def __init__(self,vocab_size,embedding_dim,hidden_dim,padding_idx,intent_num,slot_num):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,embedding_dim,padding_idx=padding_idx)\n",
        "    self.rnn=JointRnn(embedding_dim,hidden_dim)\n",
        "    self.intent_classifier=nn.Linear(hidden_dim,intent_num)\n",
        "    self.slot_classifier=nn.Linear(hidden_dim,slot_num)\n",
        "  def forward(self,data):\n",
        "    embedded=self.embedding(data)\n",
        "    rnn_output=self.rnn(embedded)\n",
        "    pooled_hidden=rnn_output.mean(dim=1)\n",
        "    intent_output=self.intent_classifier(pooled_hidden)\n",
        "    slot_output=self.slot_classifier(rnn_output)\n",
        "    return intent_output,slot_output"
      ],
      "metadata": {
        "id": "jnZVm2dO6xgF"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a model with user defined parameters"
      ],
      "metadata": {
        "id": "n88M0ZbM68JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(word_vocab)\n",
        "embed_dim=300\n",
        "padding_idx=word_vocab[\"<pad>\"]\n",
        "hidden_dim=256\n",
        "intent_num=len(intent_vocab)\n",
        "slot_num=len(slot_vocab)\n",
        "model=Joint_Model(vocab_size,embed_dim,hidden_dim,padding_idx,intent_num,slot_num)\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "2HF3kC4q65im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af89ac2f-88f2-42cb-f1cc-95297c3da05c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joint_Model(\n",
            "  (embedding): Embedding(891, 300, padding_idx=0)\n",
            "  (rnn): JointRnn(\n",
            "    (input_to_hidden): Linear(in_features=300, out_features=256, bias=True)\n",
            "    (hidden_to_hidden): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            "  (intent_classifier): Linear(in_features=256, out_features=23, bias=True)\n",
            "  (slot_classifier): Linear(in_features=256, out_features=125, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainign function"
      ],
      "metadata": {
        "id": "6sMA8pc27Fsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_joint_model(model,no_of_epochs,optimizer,intent_criterion,slot_criterion,joint_train_loader):\n",
        "  model.to(device)\n",
        "  for epoch in range(no_of_epochs):\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "    total_slot_loss=0\n",
        "    total_intent_loss=0\n",
        "    for batch in joint_train_loader:\n",
        "      text_batch=batch[\"text\"].to(device)\n",
        "      slot_batch=batch[\"slots\"].to(device)\n",
        "      intent_batch=batch[\"intent\"].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      intent_output,slot_output=model(text_batch)\n",
        "      intent_loss=intent_criterion(intent_output,intent_batch)\n",
        "      slot_loss=slot_criterion(slot_output.view(-1,slot_output.shape[-1]),slot_batch.view(-1))\n",
        "      loss=intent_loss+slot_loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss+=loss.item()\n",
        "      total_slot_loss+=slot_loss.item()\n",
        "      total_intent_loss+=intent_loss.item()\n",
        "    avg_loss = total_loss / len(joint_train_loader)\n",
        "    avg_slot_loss = total_slot_loss / len(joint_train_loader)\n",
        "    avg_intent_loss = total_intent_loss / len(joint_train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{no_of_epochs}, Total Loss: {avg_loss:.4f} , Slot Loss: {avg_slot_loss:.4f} , Intent Loss: {avg_intent_loss:.4f}\")"
      ],
      "metadata": {
        "id": "YFODUWaF7Bdd"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "slot_pad_idx=0\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "slot_criterion = nn.CrossEntropyLoss(ignore_index=slot_pad_idx)\n",
        "intent_criterion = nn.CrossEntropyLoss()\n",
        "no_of_epochs=10\n",
        "train_joint_model(model,no_of_epochs,optimizer,intent_criterion,slot_criterion,joint_train_loader)"
      ],
      "metadata": {
        "id": "Lc-GMg_G7JBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80ef188-d422-4391-9eb9-6fdcb29a225d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Total Loss: 1.0353 , Slot Loss: 0.3195 , Intent Loss: 0.7157\n",
            "Epoch 2/10, Total Loss: 0.7633 , Slot Loss: 0.2104 , Intent Loss: 0.5529\n",
            "Epoch 3/10, Total Loss: 0.6269 , Slot Loss: 0.1663 , Intent Loss: 0.4606\n",
            "Epoch 4/10, Total Loss: 0.4937 , Slot Loss: 0.1373 , Intent Loss: 0.3564\n",
            "Epoch 5/10, Total Loss: 0.3763 , Slot Loss: 0.1161 , Intent Loss: 0.2601\n",
            "Epoch 6/10, Total Loss: 0.3669 , Slot Loss: 0.1033 , Intent Loss: 0.2636\n",
            "Epoch 7/10, Total Loss: 0.3825 , Slot Loss: 0.1019 , Intent Loss: 0.2806\n",
            "Epoch 8/10, Total Loss: 0.3761 , Slot Loss: 0.0919 , Intent Loss: 0.2842\n",
            "Epoch 9/10, Total Loss: 0.3340 , Slot Loss: 0.0858 , Intent Loss: 0.2482\n",
            "Epoch 10/10, Total Loss: 0.3718 , Slot Loss: 0.0804 , Intent Loss: 0.2914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test dataloader"
      ],
      "metadata": {
        "id": "Uge3oZiH7THw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joint_test_dataset=Joint_Dataset(test_data,word_vocab,slot_vocab,intent_vocab)\n",
        "joint_test_dataloader=DataLoader(dataset=joint_test_dataset,batch_size=batch_size,shuffle=True,collate_fn=joint_collate_fn)"
      ],
      "metadata": {
        "id": "rFZmW4Cx7Qpv"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation function"
      ],
      "metadata": {
        "id": "cteyY6Vx7XzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_evaluation(model,device,test_loader):\n",
        "  model.eval()\n",
        "  slot_pad_idx=0\n",
        "  correct_intent=0\n",
        "  total_intent=0\n",
        "  correct_slots=0\n",
        "  total_slots=0\n",
        "  with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "      text=batch['text'].to(device)\n",
        "      slots=batch['slots'].to(device)\n",
        "      intent=batch['intent'].to(device)\n",
        "      intent_output,slot_output=model(text)\n",
        "      intent_preds = intent_output.argmax(dim=1)\n",
        "      correct_intent += (intent_preds == intent).sum().item()\n",
        "      total_intent += intent_preds.size(0)\n",
        "      slot_preds = slot_output.argmax(dim=-1)\n",
        "      mask = (slots!= slot_pad_idx)\n",
        "      correct_slots += ((slot_preds == slots) & mask).sum().item()\n",
        "      total_slots += mask.sum().item()\n",
        "  intent_acc = correct_intent / total_intent\n",
        "  slot_acc = correct_slots / total_slots\n",
        "  print(f\"Intent Accuracy: {intent_acc * 100:.2f}%\")\n",
        "  print(f\"Slot Accuracy: {slot_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "TKRetc6c7UmH"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joint_evaluation(model,device,joint_test_dataloader)"
      ],
      "metadata": {
        "id": "aVaOJTa67Z_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3effafc6-3278-425f-a463-8a400ba80936"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent Accuracy: 86.45%\n",
            "Slot Accuracy: 95.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inference function"
      ],
      "metadata": {
        "id": "24aoyvjJ7h2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def joint_inference(model, test_dataset, index, vocab_id, intent_id, slot_id, device):\n",
        "    sample = test_dataset[index]\n",
        "    input_tensor = sample[\"text\"].unsqueeze(0).to(device)\n",
        "    true_intent = sample[\"intent\"].item()\n",
        "    true_slots = sample[\"slots\"].tolist()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        intent_output, slot_output = model(input_tensor)\n",
        "        intent_pred = intent_output.argmax(dim=1).item()\n",
        "        slot_pred = slot_output.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
        "    text_ids = sample['text'].tolist()\n",
        "    text_deciphered = [vocab_id[word_id] for word_id in text_ids]\n",
        "    print(\"The text is:\", text_deciphered)\n",
        "    true_intent_deciphered = intent_id[true_intent]\n",
        "    pred_intent_deciphered = intent_id[intent_pred]\n",
        "    print(\"True intent:\", true_intent_deciphered)\n",
        "    print(\"Predicted intent:\", pred_intent_deciphered)\n",
        "    true_slots_deciphered = [slot_id[slot] for slot in true_slots]\n",
        "    pred_slots_deciphered = [slot_id[slot] for slot in slot_pred]\n",
        "    print(\"True slots:\", true_slots_deciphered)\n",
        "    print(\"Predicted slots:\", pred_slots_deciphered)"
      ],
      "metadata": {
        "id": "nDNeExVv7eFH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=1\n",
        "joint_inference(model,joint_test_dataset,index,vocab_id,intent_id,slot_id,device)"
      ],
      "metadata": {
        "id": "gQ7LYoN37jsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a90dff-181f-4e98-b077-4e936b7e4d54"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is: ['on', 'april', 'first', 'i', 'need', 'a', 'ticket', 'from', 'tacoma', 'to', 'san', 'jose', 'departing', 'before', '7', 'am']\n",
            "True intent: airfare\n",
            "Predicted intent: flight\n",
            "True slots: ['O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'B-depart_time.time_relative', 'B-depart_time.time', 'I-depart_time.time']\n",
            "Predicted slots: ['O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'B-depart_time.time_relative', 'B-depart_time.time', 'I-depart_time.time']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SLURP DATASET"
      ],
      "metadata": {
        "id": "pu6cvklvPDBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "uploading train file"
      ],
      "metadata": {
        "id": "pLbvM6W6PYes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "slurp_dataset=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Ghdmsis7PEez",
        "outputId": "7282b7e3-723b-4d36-c3fa-14b1613e3f0a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a21aaf9-05b9-4380-a832-810a795bb8fb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a21aaf9-05b9-4380-a832-810a795bb8fb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.jsonl to train.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def slot_generation(data):\n",
        "  words = [token['surface'] for token in data['tokens']]\n",
        "  no_of_tokens=len(words)\n",
        "  slots=[\"O\"]*no_of_tokens\n",
        "  for slot in data['entities']:\n",
        "    for idx in slot['span']:\n",
        "      slots[idx]=slot['type']\n",
        "  intent=data['intent']\n",
        "  return words,slots,intent"
      ],
      "metadata": {
        "id": "PYm8bV8FPoTc"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make train data"
      ],
      "metadata": {
        "id": "QFoRdIVmPuB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import json\n",
        "data_t=[]\n",
        "slurp_file_content=slurp_dataset['train.jsonl'].decode('utf-8')\n",
        "slurp_file=io.StringIO(slurp_file_content)\n",
        "for line in  slurp_file:\n",
        "    data_t.append(json.loads(line))"
      ],
      "metadata": {
        "id": "t4-bQmn5Pauc"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data={}\n",
        "train_data['text']=[]\n",
        "train_data['slot']=[]\n",
        "train_data['intent']=[]\n",
        "for i in range (len(data_t)):\n",
        "  words,slots,intent=slot_generation(data_t[i])\n",
        "  train_data['text'].append(words)\n",
        "  train_data['slot'].append(slots)\n",
        "  train_data['intent'].append(intent)\n",
        "no_of_samples=len(train_data['text'])\n",
        "print(no_of_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHz4-joDPccM",
        "outputId": "4c306e04-65f1-4707-bbc3-85b0c9da73eb"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data['text'][1])\n",
        "print(train_data['slot'][1])\n",
        "print(train_data['intent'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x8IXu_YQ1Kx",
        "outputId": "03608569-56a0-462a-8003-86e5cfa079bd"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'need', 'an', 'event', 'three', 'days', 'from', 'now', 'scheduled', 'with', 'amy']\n",
            "['O', 'O', 'O', 'O', 'date', 'date', 'date', 'date', 'O', 'O', 'person']\n",
            "calendar_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "make test dataset"
      ],
      "metadata": {
        "id": "zxMRNj-wTIpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "slurp_dataset=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "78c4P0Q1TxJj",
        "outputId": "92f03f4b-5a5a-4261-9da8-4af826c31d33"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-61398f1f-049e-4afa-98e8-3d5ced022706\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-61398f1f-049e-4afa-98e8-3d5ced022706\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.jsonl to test.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import json\n",
        "data_te=[]\n",
        "slurp_file_content=slurp_dataset['test.jsonl'].decode('utf-8')\n",
        "slurp_file=io.StringIO(slurp_file_content)\n",
        "for line in  slurp_file:\n",
        "    data_te.append(json.loads(line))"
      ],
      "metadata": {
        "id": "gLUMhfosTLgX"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data={}\n",
        "test_data['text']=[]\n",
        "test_data['slot']=[]\n",
        "test_data['intent']=[]\n",
        "for i in range (len(data_te)):\n",
        "  words,slots,intent=slot_generation(data_te[i])\n",
        "  test_data['text'].append(words)\n",
        "  test_data['slot'].append(slots)\n",
        "  test_data['intent'].append(intent)\n",
        "no_of_test_samples=len(test_data['text'])\n",
        "print(no_of_test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36vmxNqLTUjR",
        "outputId": "0a403afc-2aa6-4cf4-c6eb-8d67ecc143fe"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data['text'][1])\n",
        "print(test_data['slot'][1])\n",
        "print(test_data['intent'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urGzHvxMTleX",
        "outputId": "7d016a89-33b1-4f8f-cc6c-7d8de3180ef8"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['put', 'meeting', 'with', 'pawel', 'for', 'tomorrow', 'ten', 'am']\n",
            "['O', 'event_name', 'O', 'person', 'O', 'date', 'time', 'time']\n",
            "calendar_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M33d9nNuT5sj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}